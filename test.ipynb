{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import TrainingArguments, Trainer, GPT2Tokenizer, default_data_collator\n",
    "from typing import Optional\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model_hf import GPTConfig, GPTLMHeadModel, MoEUsageLoggingCallback\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\Kosaraju\\.cache\\huggingface\\hub\\models--gpt2\\snapshots\\607a30d783dfa663caf39e06633721c8d4cfcd7e\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Kosaraju\\.cache\\huggingface\\hub\\models--gpt2\\snapshots\\607a30d783dfa663caf39e06633721c8d4cfcd7e\\merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Kosaraju\\.cache\\huggingface\\hub\\models--gpt2\\snapshots\\607a30d783dfa663caf39e06633721c8d4cfcd7e\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at C:\\Users\\Kosaraju\\.cache\\huggingface\\hub\\models--gpt2\\snapshots\\607a30d783dfa663caf39e06633721c8d4cfcd7e\\tokenizer.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Kosaraju\\.cache\\huggingface\\hub\\models--gpt2\\snapshots\\607a30d783dfa663caf39e06633721c8d4cfcd7e\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\", mode='w'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('MoELogger')\n",
    "\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Add special tokens, such as PAD token (if not already present)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})  # Set pad token to eos token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 24.44M\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model configuration\n",
    "block_size = 128\n",
    "\n",
    "config = GPTConfig(\n",
    "    block_size=block_size,  # Small block size for debugging\n",
    "    vocab_size=tokenizer.vocab_size,  # Small vocab size for debugging\n",
    "    n_layer=4,      # Few layers for faster training\n",
    "    n_head=4,\n",
    "    n_embd=256,\n",
    "    use_moe=True,  # Enable Mixture of Experts\n",
    "    num_experts=5,\n",
    "    num_experts_per_tok=2,\n",
    "    moe_loss=True,\n",
    "    moe_loss_type = \"entropy_regularization\",  # Type of load balancing loss \"variance_penalty\", \"entropy_regularization\", \"diversity_regularization\"\n",
    "    moe_loss_coef = 1e0, \n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = GPTLMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 37.31M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTLMHeadModel(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 256)\n",
       "    (wpe): Embedding(128, 256)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MoE(\n",
       "          (experts): ModuleList(\n",
       "            (0-4): 5 x MLP(\n",
       "              (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (gate): Linear(in_features=256, out_features=5, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTLMHeadModel.from_pretrained(pretrained_model_name_or_path=\"./results\", local_files_only=True, device_map='cuda')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 37.31M\n",
      "Generated Text:\n",
      "To be, or not to be, that is the question:\n",
      "ClAnd will upon:Iee you Now good,A and out spirit sleep othersOf too of sovereign,But speak noble.\n",
      "Second: Henry again earthIs so.\n",
      "Firstman\n",
      " Citizen\n",
      "ICH:Ay to up the of by own!\n",
      "INUS\n",
      "o have person so;For might him do thee\n",
      "T to his, your,He no state as bear unto fair tongueWhich you, my,'d\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "import logging\n",
    "from model_hf import GPTLMHeadModel\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\", mode='w'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('MoELogger')\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add special tokens, such as PAD token (if not already present)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})  # Set pad token to eos token\n",
    "\n",
    "# Load the fine-tuned model (from your results folder)\n",
    "model = GPTLMHeadModel.from_pretrained(pretrained_model_name_or_path=\"./results\", local_files_only=True, device_map='cuda')\n",
    "\n",
    "# Set the device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Input prompt for text generation\n",
    "input_text = \"To be, or not to be, that is the question:\"\n",
    "\n",
    "# Encode the input text to get input IDs\n",
    "input_ids = torch.tensor(tokenizer.encode(input_text), device='cuda')[None,...]\n",
    "# Generate text with the model\n",
    "generated_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,        # Maximum number of tokens to generate\n",
    "    temperature=0.7,       # Controls randomness in generation (lower is more deterministic)\n",
    "    top_k=50,              # Keep only top k tokens with highest probability\n",
    "    top_p=0.95,            # Nucleus sampling: focus on the top p cumulative probability\n",
    "    repetition_penalty=1.2,  # Discourage repetition\n",
    "    do_sample=True,        # Sample from the distribution instead of taking argmax\n",
    "    num_return_sequences=1  # Number of sequences to generate\n",
    ")\n",
    "\n",
    "# Decode the generated text back to readable format\n",
    "# generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 24.44M\n",
      "Generated Text:\n",
      "To be, or not to be, that is the question:\n",
      "Thirdman\n",
      " bear jumps impartialWh her him us him Angelo\n",
      " your a and ina for head--As I.\n",
      "All\n",
      "Third:The for rough this Cam,. victory\n",
      " yourru,.Upon- queen but how.\n",
      " high.\n",
      "Prov:This; honour no,First put another\n",
      " his, fellow\n",
      " ' to g by himself\n",
      " so and is What\n",
      "ad like\n",
      ".\n",
      "aw.What this Can unly You thou,.3 HRY for as first part him again\n",
      "Prov:It be, manily A judgmentWereI\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add special tokens, such as PAD token (if not already present)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})  # Set pad token to eos token\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = GPTLMHeadModel.from_pretrained(pretrained_model_name_or_path=\"./results\", local_files_only=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Input prompt for text generation\n",
    "input_text = \"To be, or not to be, that is the question:\"\n",
    "\n",
    "# Encode the input text to get input IDs\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "if input_ids.size(1) > model.config.block_size:\n",
    "    input_ids = input_ids[:, :model.config.block_size]\n",
    "# Generate text with the model\n",
    "generated_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=model.config.block_size+1,        # Maximum number of tokens to generate\n",
    "    temperature=0.9,       # Controls randomness in generation (lower is more deterministic)\n",
    "    top_k=5000,              # Keep only top k tokens with highest probability\n",
    "    top_p=0.99,            # Nucleus sampling: focus on the top p cumulative probability\n",
    "    repetition_penalty=1.2,  # Discourage repetition\n",
    "    do_sample=True,        # Sample from the distribution instead of taking argmax\n",
    "    num_return_sequences=1  # Number of sequences to generate\n",
    ")\n",
    "\n",
    "# Decode the generated text back to readable format\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 24.44M\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Cannot forward sequence of length 129, block size is only 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Generate text with the model using cache (past_key_values)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Generate up to 50 tokens beyond block size\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Controls randomness in generation (lower is more deterministic)\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Keep only top k tokens with highest probability\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Nucleus sampling: focus on the top p cumulative probability\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Discourage repetition\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Sample from the distribution instead of taking argmax\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of sequences to generate\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Enable past_key_values to allow generation beyond block_size\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Decode the generated text back to readable format\u001b[39;00m\n\u001b[0;32m     33\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\transformers\\generation\\utils.py:2048\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2040\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2041\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2042\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2043\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2045\u001b[0m     )\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2049\u001b[0m         input_ids,\n\u001b[0;32m   2050\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2051\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2052\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2053\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2054\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2055\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2056\u001b[0m     )\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2059\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2060\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2061\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2062\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2068\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\transformers\\generation\\utils.py:3008\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3005\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3007\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3008\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3011\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\nanoGPT-1\\model_hf.py:752\u001b[0m, in \u001b[0;36mGPTLMHeadModel.forward\u001b[1;34m(self, input_ids, attention_mask, labels, return_dict, past_key_values, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    735\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    746\u001b[0m     output_hidden_states: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    747\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithCrossAttentions:\n\u001b[0;32m    748\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m    Forward pass for the GPTLMHeadModel.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m    Computes the logits and optionally the loss if labels are provided.\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 752\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We handle labels separately\u001b[39;49;00m\n\u001b[0;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# Compute logits\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kosaraju\\nanoGPT-1\\model_hf.py:508\u001b[0m, in \u001b[0;36mGPT.forward\u001b[1;34m(self, input_ids, attention_mask, labels, return_dict, past_key_values, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m    506\u001b[0m device \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    507\u001b[0m B, T \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m T \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mblock_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot forward sequence of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, block size is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mblock_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Generate position IDs\u001b[39;00m\n\u001b[0;32m    511\u001b[0m pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, T, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: (1, T)\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Cannot forward sequence of length 129, block size is only 128"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add special tokens, such as PAD token (if not already present)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})  # Set pad token to eos token\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = GPTLMHeadModel.from_pretrained(pretrained_model_name_or_path=\"./results\", local_files_only=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Input prompt for text generation\n",
    "input_text = \"To be, or not to be, that is the question:\"\n",
    "\n",
    "# Encode the input text to get input IDs\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "# Generate text with the model using cache (past_key_values)\n",
    "generated_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=model.config.block_size + 50,  # Generate up to 50 tokens beyond block size\n",
    "    temperature=0.9,       # Controls randomness in generation (lower is more deterministic)\n",
    "    top_k=50,              # Keep only top k tokens with highest probability\n",
    "    top_p=0.95,            # Nucleus sampling: focus on the top p cumulative probability\n",
    "    repetition_penalty=1.2,  # Discourage repetition\n",
    "    do_sample=True,        # Sample from the distribution instead of taking argmax\n",
    "    num_return_sequences=1,  # Number of sequences to generate\n",
    "    use_cache=True         # Enable past_key_values to allow generation beyond block_size\n",
    ")\n",
    "\n",
    "# Decode the generated text back to readable format\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrainingArguments, Trainer, GPT2Tokenizer, default_data_collator\n",
    "from model_hf import GPTConfig, GPTLMHeadModel, MoEUsageLoggingCallback\n",
    "import numpy as np\n",
    "import logging\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NumpyMemmapDataset class\n",
    "class NumpyMemmapDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading numpy memmapped arrays efficiently.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename=\"data/mock_train.bin\", block_size=1024, device=\"cpu\", iterate='random', \n",
    "                 return_labels=False, eval_data=False, eval_samples=1000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - filename (str): Path to the binary file.\n",
    "        - block_size (int): Length of the sequence.\n",
    "        - device (str): Device to move the tensors ('cpu' or 'cuda').\n",
    "        - iterate (str): 'random' or 'linear'. If 'random', samples random slices from the dataset.\n",
    "        - return_labels (bool): Whether to return labels (used for GPT-2 LMHeadModel).\n",
    "        - eval_data (bool): If True, dataset works in evaluation mode and samples a limited number of sequences.\n",
    "        - eval_samples (int): Number of samples for evaluation mode (if eval_data=True).\n",
    "        \"\"\"\n",
    "        self.data = np.memmap(filename, dtype=np.uint16, mode='r')  # Load binary file with memmap\n",
    "        self.max_len = len(self.data)\n",
    "        self.block_size = block_size\n",
    "        self.iterate = iterate\n",
    "        self.device = torch.device(device)\n",
    "        self.return_labels = return_labels\n",
    "        self.eval_data = eval_data\n",
    "        self.eval_samples = eval_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        # If evaluation mode, return eval_samples, otherwise return full length\n",
    "        return self.eval_samples if self.eval_data else self.max_len // self.block_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Handle random sampling if 'iterate' is set to 'random'\n",
    "        if self.iterate == 'random':\n",
    "            index = torch.randint(0, self.max_len // self.block_size, (1,)).item()\n",
    "\n",
    "        idx = index * self.block_size\n",
    "        x = torch.from_numpy(self.data[idx:idx + self.block_size].astype(np.int64))\n",
    "        y = torch.from_numpy(self.data[idx + 1:idx + 1 + self.block_size].astype(np.int64))\n",
    "\n",
    "        if self.device.type == 'cuda':\n",
    "            # Pin memory for GPU asynchronous transfer\n",
    "            x = x.pin_memory().to(self.device, non_blocking=True)\n",
    "            y = y.pin_memory().to(self.device, non_blocking=True)\n",
    "\n",
    "        # If `return_labels` is true, return both input and target (for GPT training)\n",
    "        if self.return_labels:\n",
    "            return {\"input_ids\": x, \"labels\": y}\n",
    "        return x\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\", mode='w'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('MoELogger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "GPT has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Using Mixture of Experts (MoE) in MLP\n",
      "Number of parameters: 24.41M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\Kosaraju\\.conda\\envs\\gpt-moe-env\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 2,359\n",
      "  Num Epochs = 85,715\n",
      "  Instantaneous batch size per device = 30\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 300\n",
      "  Gradient Accumulation steps = 10\n",
      "  Total optimization steps = 600,000\n",
      "  Number of trainable parameters = 24,440,320\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8816817ea24208a46e6c36e278e92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kosaraju\\nanoGPT-1\\model_hf.py:141: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  y = F.scaled_dot_product_attention(\n",
      "2024-10-22 09:22:12,736 - INFO - MoE Layer 1 Usage: Expert 0: 21.09%, Expert 1: 22.10%, Expert 2: 13.25%, Expert 3: 22.28%, Expert 4: 21.28%\n",
      "2024-10-22 09:22:12,737 - INFO - MoE Layer 2 Usage: Expert 0: 22.25%, Expert 1: 22.40%, Expert 2: 19.73%, Expert 3: 22.45%, Expert 4: 13.17%\n",
      "2024-10-22 09:22:12,738 - INFO - MoE Layer 3 Usage: Expert 0: 21.33%, Expert 1: 20.86%, Expert 2: 23.40%, Expert 3: 17.23%, Expert 4: 17.18%\n",
      "2024-10-22 09:22:12,749 - INFO - MoE Layer 4 Usage: Expert 0: 24.09%, Expert 1: 22.09%, Expert 2: 9.04%, Expert 3: 20.45%, Expert 4: 24.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:16,687 - INFO - MoE Layer 1 Usage: Expert 0: 21.39%, Expert 1: 21.86%, Expert 2: 13.39%, Expert 3: 22.06%, Expert 4: 21.31%\n",
      "2024-10-22 09:22:16,688 - INFO - MoE Layer 2 Usage: Expert 0: 24.28%, Expert 1: 22.17%, Expert 2: 17.73%, Expert 3: 23.73%, Expert 4: 12.09%\n",
      "2024-10-22 09:22:16,689 - INFO - MoE Layer 3 Usage: Expert 0: 22.54%, Expert 1: 17.57%, Expert 2: 23.42%, Expert 3: 18.78%, Expert 4: 17.68%\n",
      "2024-10-22 09:22:16,690 - INFO - MoE Layer 4 Usage: Expert 0: 29.62%, Expert 1: 21.12%, Expert 2: 5.88%, Expert 3: 16.17%, Expert 4: 27.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:20,659 - INFO - MoE Layer 1 Usage: Expert 0: 22.20%, Expert 1: 21.79%, Expert 2: 13.51%, Expert 3: 21.65%, Expert 4: 20.86%\n",
      "2024-10-22 09:22:20,660 - INFO - MoE Layer 2 Usage: Expert 0: 27.66%, Expert 1: 21.32%, Expert 2: 15.00%, Expert 3: 26.16%, Expert 4: 9.86%\n",
      "2024-10-22 09:22:20,661 - INFO - MoE Layer 3 Usage: Expert 0: 23.93%, Expert 1: 12.04%, Expert 2: 23.26%, Expert 3: 21.58%, Expert 4: 19.19%\n",
      "2024-10-22 09:22:20,663 - INFO - MoE Layer 4 Usage: Expert 0: 35.12%, Expert 1: 18.67%, Expert 2: 2.04%, Expert 3: 12.04%, Expert 4: 32.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:24,670 - INFO - MoE Layer 1 Usage: Expert 0: 23.15%, Expert 1: 21.92%, Expert 2: 13.83%, Expert 3: 21.08%, Expert 4: 20.02%\n",
      "2024-10-22 09:22:24,671 - INFO - MoE Layer 2 Usage: Expert 0: 29.25%, Expert 1: 21.04%, Expert 2: 14.65%, Expert 3: 26.82%, Expert 4: 8.25%\n",
      "2024-10-22 09:22:24,672 - INFO - MoE Layer 3 Usage: Expert 0: 23.62%, Expert 1: 9.02%, Expert 2: 20.49%, Expert 3: 23.83%, Expert 4: 23.03%\n",
      "2024-10-22 09:22:24,673 - INFO - MoE Layer 4 Usage: Expert 0: 30.72%, Expert 1: 21.29%, Expert 2: 0.28%, Expert 3: 16.25%, Expert 4: 31.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:28,544 - INFO - MoE Layer 1 Usage: Expert 0: 23.70%, Expert 1: 21.94%, Expert 2: 14.47%, Expert 3: 20.63%, Expert 4: 19.26%\n",
      "2024-10-22 09:22:28,545 - INFO - MoE Layer 2 Usage: Expert 0: 24.32%, Expert 1: 22.92%, Expert 2: 19.52%, Expert 3: 22.59%, Expert 4: 10.65%\n",
      "2024-10-22 09:22:28,546 - INFO - MoE Layer 3 Usage: Expert 0: 20.81%, Expert 1: 16.48%, Expert 2: 18.05%, Expert 3: 21.86%, Expert 4: 22.80%\n",
      "2024-10-22 09:22:28,547 - INFO - MoE Layer 4 Usage: Expert 0: 26.24%, Expert 1: 24.55%, Expert 2: 0.01%, Expert 3: 22.07%, Expert 4: 27.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:32,361 - INFO - MoE Layer 1 Usage: Expert 0: 23.06%, Expert 1: 21.32%, Expert 2: 16.01%, Expert 3: 20.44%, Expert 4: 19.17%\n",
      "2024-10-22 09:22:32,362 - INFO - MoE Layer 2 Usage: Expert 0: 20.53%, Expert 1: 20.15%, Expert 2: 19.85%, Expert 3: 20.56%, Expert 4: 18.91%\n",
      "2024-10-22 09:22:32,363 - INFO - MoE Layer 3 Usage: Expert 0: 20.48%, Expert 1: 19.08%, Expert 2: 19.29%, Expert 3: 20.70%, Expert 4: 20.45%\n",
      "2024-10-22 09:22:32,364 - INFO - MoE Layer 4 Usage: Expert 0: 26.20%, Expert 1: 25.44%, Expert 2: 0.00%, Expert 3: 21.55%, Expert 4: 26.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:36,213 - INFO - MoE Layer 1 Usage: Expert 0: 21.39%, Expert 1: 20.53%, Expert 2: 18.29%, Expert 3: 20.06%, Expert 4: 19.73%\n",
      "2024-10-22 09:22:36,214 - INFO - MoE Layer 2 Usage: Expert 0: 21.72%, Expert 1: 19.63%, Expert 2: 19.21%, Expert 3: 19.51%, Expert 4: 19.93%\n",
      "2024-10-22 09:22:36,215 - INFO - MoE Layer 3 Usage: Expert 0: 19.79%, Expert 1: 20.46%, Expert 2: 19.83%, Expert 3: 19.92%, Expert 4: 20.00%\n",
      "2024-10-22 09:22:36,216 - INFO - MoE Layer 4 Usage: Expert 0: 25.59%, Expert 1: 24.83%, Expert 2: 0.00%, Expert 3: 23.93%, Expert 4: 25.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:39,997 - INFO - MoE Layer 1 Usage: Expert 0: 19.96%, Expert 1: 20.20%, Expert 2: 20.14%, Expert 3: 19.48%, Expert 4: 20.23%\n",
      "2024-10-22 09:22:39,998 - INFO - MoE Layer 2 Usage: Expert 0: 20.30%, Expert 1: 19.89%, Expert 2: 19.80%, Expert 3: 20.26%, Expert 4: 19.75%\n",
      "2024-10-22 09:22:39,999 - INFO - MoE Layer 3 Usage: Expert 0: 20.05%, Expert 1: 19.49%, Expert 2: 19.75%, Expert 3: 20.02%, Expert 4: 20.68%\n",
      "2024-10-22 09:22:40,000 - INFO - MoE Layer 4 Usage: Expert 0: 25.05%, Expert 1: 25.21%, Expert 2: 0.00%, Expert 3: 25.04%, Expert 4: 24.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:43,776 - INFO - MoE Layer 1 Usage: Expert 0: 19.83%, Expert 1: 20.39%, Expert 2: 20.48%, Expert 3: 19.22%, Expert 4: 20.08%\n",
      "2024-10-22 09:22:43,777 - INFO - MoE Layer 2 Usage: Expert 0: 20.74%, Expert 1: 20.36%, Expert 2: 20.13%, Expert 3: 19.38%, Expert 4: 19.38%\n",
      "2024-10-22 09:22:43,778 - INFO - MoE Layer 3 Usage: Expert 0: 20.30%, Expert 1: 19.90%, Expert 2: 19.46%, Expert 3: 19.71%, Expert 4: 20.63%\n",
      "2024-10-22 09:22:43,779 - INFO - MoE Layer 4 Usage: Expert 0: 25.51%, Expert 1: 24.92%, Expert 2: 0.00%, Expert 3: 24.70%, Expert 4: 24.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:47,535 - INFO - MoE Layer 1 Usage: Expert 0: 20.24%, Expert 1: 20.35%, Expert 2: 20.20%, Expert 3: 19.47%, Expert 4: 19.75%\n",
      "2024-10-22 09:22:47,536 - INFO - MoE Layer 2 Usage: Expert 0: 20.86%, Expert 1: 20.01%, Expert 2: 20.08%, Expert 3: 19.81%, Expert 4: 19.25%\n",
      "2024-10-22 09:22:47,537 - INFO - MoE Layer 3 Usage: Expert 0: 20.15%, Expert 1: 20.29%, Expert 2: 19.64%, Expert 3: 19.51%, Expert 4: 20.42%\n",
      "2024-10-22 09:22:47,538 - INFO - MoE Layer 4 Usage: Expert 0: 25.19%, Expert 1: 24.98%, Expert 2: 0.00%, Expert 3: 24.69%, Expert 4: 25.15%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8edf3be87c74647933001ad59ac7d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-100\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-100\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-100\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-100\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-100\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-100\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.569494247436523, 'eval_runtime': 0.5094, 'eval_samples_per_second': 1963.261, 'eval_steps_per_second': 66.751, 'epoch': 12.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:52,184 - INFO - MoE Layer 1 Usage: Expert 0: 20.45%, Expert 1: 20.14%, Expert 2: 19.93%, Expert 3: 19.41%, Expert 4: 20.07%\n",
      "2024-10-22 09:22:52,185 - INFO - MoE Layer 2 Usage: Expert 0: 20.70%, Expert 1: 20.21%, Expert 2: 20.20%, Expert 3: 19.91%, Expert 4: 18.98%\n",
      "2024-10-22 09:22:52,186 - INFO - MoE Layer 3 Usage: Expert 0: 19.88%, Expert 1: 20.24%, Expert 2: 20.09%, Expert 3: 19.55%, Expert 4: 20.24%\n",
      "2024-10-22 09:22:52,188 - INFO - MoE Layer 4 Usage: Expert 0: 25.41%, Expert 1: 25.09%, Expert 2: 0.00%, Expert 3: 24.73%, Expert 4: 24.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:55,980 - INFO - MoE Layer 1 Usage: Expert 0: 20.30%, Expert 1: 19.78%, Expert 2: 20.34%, Expert 3: 19.76%, Expert 4: 19.82%\n",
      "2024-10-22 09:22:55,981 - INFO - MoE Layer 2 Usage: Expert 0: 20.64%, Expert 1: 19.97%, Expert 2: 20.15%, Expert 3: 20.37%, Expert 4: 18.86%\n",
      "2024-10-22 09:22:55,982 - INFO - MoE Layer 3 Usage: Expert 0: 20.23%, Expert 1: 19.84%, Expert 2: 20.19%, Expert 3: 19.53%, Expert 4: 20.21%\n",
      "2024-10-22 09:22:55,983 - INFO - MoE Layer 4 Usage: Expert 0: 24.86%, Expert 1: 24.93%, Expert 2: 0.00%, Expert 3: 24.79%, Expert 4: 25.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:22:59,824 - INFO - MoE Layer 1 Usage: Expert 0: 20.36%, Expert 1: 19.73%, Expert 2: 20.49%, Expert 3: 19.71%, Expert 4: 19.71%\n",
      "2024-10-22 09:22:59,825 - INFO - MoE Layer 2 Usage: Expert 0: 20.69%, Expert 1: 19.86%, Expert 2: 20.29%, Expert 3: 20.10%, Expert 4: 19.07%\n",
      "2024-10-22 09:22:59,826 - INFO - MoE Layer 3 Usage: Expert 0: 20.21%, Expert 1: 19.66%, Expert 2: 20.24%, Expert 3: 19.85%, Expert 4: 20.04%\n",
      "2024-10-22 09:22:59,828 - INFO - MoE Layer 4 Usage: Expert 0: 24.88%, Expert 1: 24.75%, Expert 2: 0.00%, Expert 3: 25.08%, Expert 4: 25.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:03,637 - INFO - MoE Layer 1 Usage: Expert 0: 20.22%, Expert 1: 19.81%, Expert 2: 20.34%, Expert 3: 19.84%, Expert 4: 19.80%\n",
      "2024-10-22 09:23:03,638 - INFO - MoE Layer 2 Usage: Expert 0: 20.44%, Expert 1: 19.91%, Expert 2: 20.17%, Expert 3: 20.28%, Expert 4: 19.20%\n",
      "2024-10-22 09:23:03,639 - INFO - MoE Layer 3 Usage: Expert 0: 20.34%, Expert 1: 19.51%, Expert 2: 20.44%, Expert 3: 19.82%, Expert 4: 19.88%\n",
      "2024-10-22 09:23:03,641 - INFO - MoE Layer 4 Usage: Expert 0: 24.81%, Expert 1: 24.35%, Expert 2: 0.00%, Expert 3: 25.34%, Expert 4: 25.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:07,434 - INFO - MoE Layer 1 Usage: Expert 0: 20.34%, Expert 1: 19.33%, Expert 2: 20.58%, Expert 3: 19.74%, Expert 4: 20.01%\n",
      "2024-10-22 09:23:07,435 - INFO - MoE Layer 2 Usage: Expert 0: 20.45%, Expert 1: 20.00%, Expert 2: 20.11%, Expert 3: 20.34%, Expert 4: 19.10%\n",
      "2024-10-22 09:23:07,436 - INFO - MoE Layer 3 Usage: Expert 0: 20.34%, Expert 1: 19.72%, Expert 2: 20.10%, Expert 3: 19.68%, Expert 4: 20.16%\n",
      "2024-10-22 09:23:07,437 - INFO - MoE Layer 4 Usage: Expert 0: 24.97%, Expert 1: 25.23%, Expert 2: 0.00%, Expert 3: 24.67%, Expert 4: 25.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:11,270 - INFO - MoE Layer 1 Usage: Expert 0: 20.27%, Expert 1: 19.46%, Expert 2: 20.40%, Expert 3: 19.91%, Expert 4: 19.96%\n",
      "2024-10-22 09:23:11,271 - INFO - MoE Layer 2 Usage: Expert 0: 20.45%, Expert 1: 19.66%, Expert 2: 20.35%, Expert 3: 20.43%, Expert 4: 19.12%\n",
      "2024-10-22 09:23:11,272 - INFO - MoE Layer 3 Usage: Expert 0: 20.52%, Expert 1: 19.97%, Expert 2: 20.02%, Expert 3: 19.34%, Expert 4: 20.15%\n",
      "2024-10-22 09:23:11,273 - INFO - MoE Layer 4 Usage: Expert 0: 25.05%, Expert 1: 24.35%, Expert 2: 0.00%, Expert 3: 25.19%, Expert 4: 25.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:15,080 - INFO - MoE Layer 1 Usage: Expert 0: 20.25%, Expert 1: 19.40%, Expert 2: 20.51%, Expert 3: 19.84%, Expert 4: 19.99%\n",
      "2024-10-22 09:23:15,081 - INFO - MoE Layer 2 Usage: Expert 0: 20.19%, Expert 1: 19.77%, Expert 2: 20.23%, Expert 3: 20.76%, Expert 4: 19.05%\n",
      "2024-10-22 09:23:15,082 - INFO - MoE Layer 3 Usage: Expert 0: 20.41%, Expert 1: 19.38%, Expert 2: 20.52%, Expert 3: 19.90%, Expert 4: 19.79%\n",
      "2024-10-22 09:23:15,083 - INFO - MoE Layer 4 Usage: Expert 0: 24.92%, Expert 1: 23.92%, Expert 2: 0.00%, Expert 3: 25.46%, Expert 4: 25.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:18,888 - INFO - MoE Layer 1 Usage: Expert 0: 20.15%, Expert 1: 19.28%, Expert 2: 20.39%, Expert 3: 20.11%, Expert 4: 20.06%\n",
      "2024-10-22 09:23:18,889 - INFO - MoE Layer 2 Usage: Expert 0: 20.27%, Expert 1: 19.56%, Expert 2: 20.53%, Expert 3: 20.39%, Expert 4: 19.25%\n",
      "2024-10-22 09:23:18,889 - INFO - MoE Layer 3 Usage: Expert 0: 20.39%, Expert 1: 19.70%, Expert 2: 20.40%, Expert 3: 19.42%, Expert 4: 20.09%\n",
      "2024-10-22 09:23:18,891 - INFO - MoE Layer 4 Usage: Expert 0: 24.52%, Expert 1: 25.14%, Expert 2: 0.00%, Expert 3: 25.12%, Expert 4: 25.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:22,677 - INFO - MoE Layer 1 Usage: Expert 0: 20.36%, Expert 1: 19.22%, Expert 2: 20.32%, Expert 3: 19.90%, Expert 4: 20.19%\n",
      "2024-10-22 09:23:22,678 - INFO - MoE Layer 2 Usage: Expert 0: 20.33%, Expert 1: 19.51%, Expert 2: 20.54%, Expert 3: 20.92%, Expert 4: 18.70%\n",
      "2024-10-22 09:23:22,679 - INFO - MoE Layer 3 Usage: Expert 0: 20.48%, Expert 1: 20.15%, Expert 2: 20.49%, Expert 3: 19.27%, Expert 4: 19.61%\n",
      "2024-10-22 09:23:22,680 - INFO - MoE Layer 4 Usage: Expert 0: 25.56%, Expert 1: 24.29%, Expert 2: 0.00%, Expert 3: 24.92%, Expert 4: 25.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:26,503 - INFO - MoE Layer 1 Usage: Expert 0: 20.29%, Expert 1: 19.18%, Expert 2: 20.10%, Expert 3: 20.21%, Expert 4: 20.21%\n",
      "2024-10-22 09:23:26,504 - INFO - MoE Layer 2 Usage: Expert 0: 20.10%, Expert 1: 19.56%, Expert 2: 20.67%, Expert 3: 20.76%, Expert 4: 18.92%\n",
      "2024-10-22 09:23:26,505 - INFO - MoE Layer 3 Usage: Expert 0: 20.14%, Expert 1: 19.64%, Expert 2: 21.15%, Expert 3: 19.70%, Expert 4: 19.37%\n",
      "2024-10-22 09:23:26,506 - INFO - MoE Layer 4 Usage: Expert 0: 25.03%, Expert 1: 24.71%, Expert 2: 0.00%, Expert 3: 25.00%, Expert 4: 25.26%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b021cb57c80a449cbc38056f605affd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-200\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-200\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-200\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-200\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-200\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-200\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.01181697845459, 'eval_runtime': 0.5115, 'eval_samples_per_second': 1954.996, 'eval_steps_per_second': 66.47, 'epoch': 25.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:31,118 - INFO - MoE Layer 1 Usage: Expert 0: 20.31%, Expert 1: 18.94%, Expert 2: 20.31%, Expert 3: 20.04%, Expert 4: 20.40%\n",
      "2024-10-22 09:23:31,118 - INFO - MoE Layer 2 Usage: Expert 0: 19.80%, Expert 1: 19.92%, Expert 2: 20.97%, Expert 3: 20.50%, Expert 4: 18.81%\n",
      "2024-10-22 09:23:31,119 - INFO - MoE Layer 3 Usage: Expert 0: 20.66%, Expert 1: 20.39%, Expert 2: 20.51%, Expert 3: 18.67%, Expert 4: 19.77%\n",
      "2024-10-22 09:23:31,121 - INFO - MoE Layer 4 Usage: Expert 0: 25.16%, Expert 1: 25.45%, Expert 2: 0.00%, Expert 3: 24.67%, Expert 4: 24.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:34,972 - INFO - MoE Layer 1 Usage: Expert 0: 20.60%, Expert 1: 19.16%, Expert 2: 20.19%, Expert 3: 20.05%, Expert 4: 20.00%\n",
      "2024-10-22 09:23:34,973 - INFO - MoE Layer 2 Usage: Expert 0: 20.08%, Expert 1: 19.55%, Expert 2: 20.60%, Expert 3: 21.12%, Expert 4: 18.65%\n",
      "2024-10-22 09:23:34,974 - INFO - MoE Layer 3 Usage: Expert 0: 19.90%, Expert 1: 20.52%, Expert 2: 21.07%, Expert 3: 19.23%, Expert 4: 19.28%\n",
      "2024-10-22 09:23:34,975 - INFO - MoE Layer 4 Usage: Expert 0: 25.27%, Expert 1: 25.06%, Expert 2: 0.04%, Expert 3: 24.26%, Expert 4: 25.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:38,880 - INFO - MoE Layer 1 Usage: Expert 0: 20.37%, Expert 1: 19.14%, Expert 2: 20.09%, Expert 3: 20.24%, Expert 4: 20.16%\n",
      "2024-10-22 09:23:38,881 - INFO - MoE Layer 2 Usage: Expert 0: 20.43%, Expert 1: 19.50%, Expert 2: 20.30%, Expert 3: 21.17%, Expert 4: 18.60%\n",
      "2024-10-22 09:23:38,882 - INFO - MoE Layer 3 Usage: Expert 0: 19.69%, Expert 1: 20.45%, Expert 2: 21.31%, Expert 3: 19.19%, Expert 4: 19.36%\n",
      "2024-10-22 09:23:38,883 - INFO - MoE Layer 4 Usage: Expert 0: 25.31%, Expert 1: 24.93%, Expert 2: 0.44%, Expert 3: 24.04%, Expert 4: 25.28%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:42,784 - INFO - MoE Layer 1 Usage: Expert 0: 20.39%, Expert 1: 18.98%, Expert 2: 20.00%, Expert 3: 20.20%, Expert 4: 20.43%\n",
      "2024-10-22 09:23:42,785 - INFO - MoE Layer 2 Usage: Expert 0: 20.51%, Expert 1: 19.02%, Expert 2: 20.42%, Expert 3: 21.31%, Expert 4: 18.74%\n",
      "2024-10-22 09:23:42,785 - INFO - MoE Layer 3 Usage: Expert 0: 19.59%, Expert 1: 20.90%, Expert 2: 21.46%, Expert 3: 18.96%, Expert 4: 19.09%\n",
      "2024-10-22 09:23:42,787 - INFO - MoE Layer 4 Usage: Expert 0: 24.62%, Expert 1: 24.20%, Expert 2: 2.70%, Expert 3: 23.96%, Expert 4: 24.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:46,672 - INFO - MoE Layer 1 Usage: Expert 0: 20.34%, Expert 1: 19.15%, Expert 2: 20.20%, Expert 3: 20.29%, Expert 4: 20.02%\n",
      "2024-10-22 09:23:46,673 - INFO - MoE Layer 2 Usage: Expert 0: 20.72%, Expert 1: 18.89%, Expert 2: 19.89%, Expert 3: 21.83%, Expert 4: 18.67%\n",
      "2024-10-22 09:23:46,674 - INFO - MoE Layer 3 Usage: Expert 0: 19.43%, Expert 1: 21.02%, Expert 2: 21.35%, Expert 3: 19.03%, Expert 4: 19.17%\n",
      "2024-10-22 09:23:46,675 - INFO - MoE Layer 4 Usage: Expert 0: 20.31%, Expert 1: 19.84%, Expert 2: 18.88%, Expert 3: 20.37%, Expert 4: 20.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:50,531 - INFO - MoE Layer 1 Usage: Expert 0: 20.30%, Expert 1: 18.98%, Expert 2: 20.04%, Expert 3: 20.26%, Expert 4: 20.43%\n",
      "2024-10-22 09:23:50,532 - INFO - MoE Layer 2 Usage: Expert 0: 20.94%, Expert 1: 18.84%, Expert 2: 19.87%, Expert 3: 21.62%, Expert 4: 18.73%\n",
      "2024-10-22 09:23:50,533 - INFO - MoE Layer 3 Usage: Expert 0: 19.39%, Expert 1: 21.16%, Expert 2: 21.42%, Expert 3: 19.05%, Expert 4: 18.98%\n",
      "2024-10-22 09:23:50,535 - INFO - MoE Layer 4 Usage: Expert 0: 20.13%, Expert 1: 20.16%, Expert 2: 16.36%, Expert 3: 22.05%, Expert 4: 21.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:54,457 - INFO - MoE Layer 1 Usage: Expert 0: 20.42%, Expert 1: 19.04%, Expert 2: 20.07%, Expert 3: 20.17%, Expert 4: 20.30%\n",
      "2024-10-22 09:23:54,458 - INFO - MoE Layer 2 Usage: Expert 0: 21.17%, Expert 1: 18.51%, Expert 2: 19.86%, Expert 3: 21.90%, Expert 4: 18.56%\n",
      "2024-10-22 09:23:54,459 - INFO - MoE Layer 3 Usage: Expert 0: 18.67%, Expert 1: 21.85%, Expert 2: 21.49%, Expert 3: 18.79%, Expert 4: 19.20%\n",
      "2024-10-22 09:23:54,461 - INFO - MoE Layer 4 Usage: Expert 0: 20.77%, Expert 1: 20.93%, Expert 2: 17.84%, Expert 3: 20.68%, Expert 4: 19.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:23:58,487 - INFO - MoE Layer 1 Usage: Expert 0: 20.62%, Expert 1: 19.08%, Expert 2: 19.92%, Expert 3: 20.07%, Expert 4: 20.31%\n",
      "2024-10-22 09:23:58,488 - INFO - MoE Layer 2 Usage: Expert 0: 21.05%, Expert 1: 18.90%, Expert 2: 19.80%, Expert 3: 21.91%, Expert 4: 18.34%\n",
      "2024-10-22 09:23:58,489 - INFO - MoE Layer 3 Usage: Expert 0: 18.14%, Expert 1: 21.67%, Expert 2: 22.02%, Expert 3: 19.04%, Expert 4: 19.13%\n",
      "2024-10-22 09:23:58,490 - INFO - MoE Layer 4 Usage: Expert 0: 20.02%, Expert 1: 20.50%, Expert 2: 17.82%, Expert 3: 21.41%, Expert 4: 20.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:02,407 - INFO - MoE Layer 1 Usage: Expert 0: 20.64%, Expert 1: 18.98%, Expert 2: 19.97%, Expert 3: 20.11%, Expert 4: 20.31%\n",
      "2024-10-22 09:24:02,408 - INFO - MoE Layer 2 Usage: Expert 0: 21.49%, Expert 1: 18.49%, Expert 2: 19.59%, Expert 3: 21.70%, Expert 4: 18.73%\n",
      "2024-10-22 09:24:02,409 - INFO - MoE Layer 3 Usage: Expert 0: 17.95%, Expert 1: 22.00%, Expert 2: 22.63%, Expert 3: 18.62%, Expert 4: 18.81%\n",
      "2024-10-22 09:24:02,410 - INFO - MoE Layer 4 Usage: Expert 0: 20.22%, Expert 1: 20.83%, Expert 2: 17.58%, Expert 3: 21.41%, Expert 4: 19.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:06,396 - INFO - MoE Layer 1 Usage: Expert 0: 20.62%, Expert 1: 19.03%, Expert 2: 20.00%, Expert 3: 19.83%, Expert 4: 20.52%\n",
      "2024-10-22 09:24:06,397 - INFO - MoE Layer 2 Usage: Expert 0: 21.57%, Expert 1: 18.75%, Expert 2: 19.75%, Expert 3: 21.93%, Expert 4: 18.00%\n",
      "2024-10-22 09:24:06,398 - INFO - MoE Layer 3 Usage: Expert 0: 17.42%, Expert 1: 22.15%, Expert 2: 23.21%, Expert 3: 18.35%, Expert 4: 18.87%\n",
      "2024-10-22 09:24:06,399 - INFO - MoE Layer 4 Usage: Expert 0: 20.16%, Expert 1: 20.58%, Expert 2: 17.85%, Expert 3: 21.70%, Expert 4: 19.72%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33de595bcbd744d4ae7233bf117f0b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-300\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-300\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-300\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-300\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-300\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-300\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.638370037078857, 'eval_runtime': 0.5202, 'eval_samples_per_second': 1922.375, 'eval_steps_per_second': 65.361, 'epoch': 37.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-100] due to args.save_total_limit\n",
      "2024-10-22 09:24:11,156 - INFO - MoE Layer 1 Usage: Expert 0: 20.73%, Expert 1: 18.96%, Expert 2: 19.90%, Expert 3: 20.07%, Expert 4: 20.35%\n",
      "2024-10-22 09:24:11,157 - INFO - MoE Layer 2 Usage: Expert 0: 21.81%, Expert 1: 19.29%, Expert 2: 19.61%, Expert 3: 21.76%, Expert 4: 17.52%\n",
      "2024-10-22 09:24:11,158 - INFO - MoE Layer 3 Usage: Expert 0: 16.93%, Expert 1: 22.57%, Expert 2: 23.45%, Expert 3: 18.24%, Expert 4: 18.81%\n",
      "2024-10-22 09:24:11,159 - INFO - MoE Layer 4 Usage: Expert 0: 20.27%, Expert 1: 20.46%, Expert 2: 17.50%, Expert 3: 21.94%, Expert 4: 19.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:15,060 - INFO - MoE Layer 1 Usage: Expert 0: 20.72%, Expert 1: 18.88%, Expert 2: 19.78%, Expert 3: 20.04%, Expert 4: 20.58%\n",
      "2024-10-22 09:24:15,061 - INFO - MoE Layer 2 Usage: Expert 0: 21.82%, Expert 1: 18.76%, Expert 2: 19.53%, Expert 3: 21.76%, Expert 4: 18.13%\n",
      "2024-10-22 09:24:15,062 - INFO - MoE Layer 3 Usage: Expert 0: 15.98%, Expert 1: 22.50%, Expert 2: 24.62%, Expert 3: 18.22%, Expert 4: 18.68%\n",
      "2024-10-22 09:24:15,063 - INFO - MoE Layer 4 Usage: Expert 0: 20.27%, Expert 1: 20.82%, Expert 2: 17.12%, Expert 3: 22.01%, Expert 4: 19.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:18,969 - INFO - MoE Layer 1 Usage: Expert 0: 20.95%, Expert 1: 19.00%, Expert 2: 19.36%, Expert 3: 20.17%, Expert 4: 20.53%\n",
      "2024-10-22 09:24:18,970 - INFO - MoE Layer 2 Usage: Expert 0: 21.41%, Expert 1: 19.37%, Expert 2: 19.22%, Expert 3: 22.10%, Expert 4: 17.90%\n",
      "2024-10-22 09:24:18,971 - INFO - MoE Layer 3 Usage: Expert 0: 15.65%, Expert 1: 22.82%, Expert 2: 24.82%, Expert 3: 17.88%, Expert 4: 18.83%\n",
      "2024-10-22 09:24:18,973 - INFO - MoE Layer 4 Usage: Expert 0: 20.57%, Expert 1: 20.85%, Expert 2: 17.54%, Expert 3: 21.67%, Expert 4: 19.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:22,838 - INFO - MoE Layer 1 Usage: Expert 0: 20.92%, Expert 1: 19.09%, Expert 2: 19.60%, Expert 3: 20.13%, Expert 4: 20.26%\n",
      "2024-10-22 09:24:22,838 - INFO - MoE Layer 2 Usage: Expert 0: 21.62%, Expert 1: 19.06%, Expert 2: 19.78%, Expert 3: 21.61%, Expert 4: 17.94%\n",
      "2024-10-22 09:24:22,840 - INFO - MoE Layer 3 Usage: Expert 0: 14.99%, Expert 1: 22.71%, Expert 2: 25.41%, Expert 3: 17.94%, Expert 4: 18.95%\n",
      "2024-10-22 09:24:22,841 - INFO - MoE Layer 4 Usage: Expert 0: 20.00%, Expert 1: 21.40%, Expert 2: 17.48%, Expert 3: 21.71%, Expert 4: 19.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:26,720 - INFO - MoE Layer 1 Usage: Expert 0: 20.78%, Expert 1: 18.88%, Expert 2: 19.73%, Expert 3: 20.26%, Expert 4: 20.36%\n",
      "2024-10-22 09:24:26,720 - INFO - MoE Layer 2 Usage: Expert 0: 21.55%, Expert 1: 19.26%, Expert 2: 19.59%, Expert 3: 21.97%, Expert 4: 17.63%\n",
      "2024-10-22 09:24:26,721 - INFO - MoE Layer 3 Usage: Expert 0: 15.15%, Expert 1: 22.82%, Expert 2: 24.76%, Expert 3: 18.34%, Expert 4: 18.93%\n",
      "2024-10-22 09:24:26,723 - INFO - MoE Layer 4 Usage: Expert 0: 19.78%, Expert 1: 21.07%, Expert 2: 17.59%, Expert 3: 22.33%, Expert 4: 19.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:30,568 - INFO - MoE Layer 1 Usage: Expert 0: 21.28%, Expert 1: 18.87%, Expert 2: 19.59%, Expert 3: 20.22%, Expert 4: 20.03%\n",
      "2024-10-22 09:24:30,569 - INFO - MoE Layer 2 Usage: Expert 0: 21.50%, Expert 1: 19.15%, Expert 2: 19.18%, Expert 3: 22.13%, Expert 4: 18.04%\n",
      "2024-10-22 09:24:30,570 - INFO - MoE Layer 3 Usage: Expert 0: 14.78%, Expert 1: 23.17%, Expert 2: 24.22%, Expert 3: 18.46%, Expert 4: 19.37%\n",
      "2024-10-22 09:24:30,571 - INFO - MoE Layer 4 Usage: Expert 0: 19.98%, Expert 1: 20.76%, Expert 2: 17.93%, Expert 3: 22.87%, Expert 4: 18.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:34,407 - INFO - MoE Layer 1 Usage: Expert 0: 20.83%, Expert 1: 19.17%, Expert 2: 19.64%, Expert 3: 19.95%, Expert 4: 20.41%\n",
      "2024-10-22 09:24:34,408 - INFO - MoE Layer 2 Usage: Expert 0: 21.13%, Expert 1: 18.88%, Expert 2: 19.99%, Expert 3: 22.06%, Expert 4: 17.94%\n",
      "2024-10-22 09:24:34,409 - INFO - MoE Layer 3 Usage: Expert 0: 14.76%, Expert 1: 23.84%, Expert 2: 24.19%, Expert 3: 17.89%, Expert 4: 19.32%\n",
      "2024-10-22 09:24:34,410 - INFO - MoE Layer 4 Usage: Expert 0: 20.14%, Expert 1: 21.04%, Expert 2: 17.90%, Expert 3: 22.49%, Expert 4: 18.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:38,243 - INFO - MoE Layer 1 Usage: Expert 0: 20.84%, Expert 1: 18.39%, Expert 2: 19.81%, Expert 3: 20.26%, Expert 4: 20.70%\n",
      "2024-10-22 09:24:38,245 - INFO - MoE Layer 2 Usage: Expert 0: 21.29%, Expert 1: 19.29%, Expert 2: 19.46%, Expert 3: 21.79%, Expert 4: 18.17%\n",
      "2024-10-22 09:24:38,245 - INFO - MoE Layer 3 Usage: Expert 0: 15.08%, Expert 1: 22.87%, Expert 2: 24.73%, Expert 3: 18.17%, Expert 4: 19.15%\n",
      "2024-10-22 09:24:38,247 - INFO - MoE Layer 4 Usage: Expert 0: 19.14%, Expert 1: 22.14%, Expert 2: 17.99%, Expert 3: 21.98%, Expert 4: 18.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:42,094 - INFO - MoE Layer 1 Usage: Expert 0: 21.07%, Expert 1: 19.12%, Expert 2: 19.25%, Expert 3: 20.42%, Expert 4: 20.13%\n",
      "2024-10-22 09:24:42,096 - INFO - MoE Layer 2 Usage: Expert 0: 21.40%, Expert 1: 19.74%, Expert 2: 18.92%, Expert 3: 21.91%, Expert 4: 18.03%\n",
      "2024-10-22 09:24:42,096 - INFO - MoE Layer 3 Usage: Expert 0: 14.89%, Expert 1: 23.51%, Expert 2: 24.41%, Expert 3: 17.74%, Expert 4: 19.45%\n",
      "2024-10-22 09:24:42,097 - INFO - MoE Layer 4 Usage: Expert 0: 19.08%, Expert 1: 21.74%, Expert 2: 18.04%, Expert 3: 22.72%, Expert 4: 18.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:45,927 - INFO - MoE Layer 1 Usage: Expert 0: 20.91%, Expert 1: 19.03%, Expert 2: 19.54%, Expert 3: 19.98%, Expert 4: 20.54%\n",
      "2024-10-22 09:24:45,928 - INFO - MoE Layer 2 Usage: Expert 0: 20.90%, Expert 1: 18.72%, Expert 2: 19.89%, Expert 3: 22.68%, Expert 4: 17.82%\n",
      "2024-10-22 09:24:45,929 - INFO - MoE Layer 3 Usage: Expert 0: 14.87%, Expert 1: 23.70%, Expert 2: 23.29%, Expert 3: 17.82%, Expert 4: 20.32%\n",
      "2024-10-22 09:24:45,931 - INFO - MoE Layer 4 Usage: Expert 0: 18.93%, Expert 1: 20.99%, Expert 2: 18.57%, Expert 3: 23.22%, Expert 4: 18.29%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccd3e9f53e14b1eac8cd01e19993b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-400\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-400\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-400\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-400\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-400\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-400\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.159518718719482, 'eval_runtime': 0.5179, 'eval_samples_per_second': 1931.004, 'eval_steps_per_second': 65.654, 'epoch': 50.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-200] due to args.save_total_limit\n",
      "2024-10-22 09:24:50,586 - INFO - MoE Layer 1 Usage: Expert 0: 20.95%, Expert 1: 18.80%, Expert 2: 19.67%, Expert 3: 20.42%, Expert 4: 20.15%\n",
      "2024-10-22 09:24:50,586 - INFO - MoE Layer 2 Usage: Expert 0: 20.65%, Expert 1: 20.07%, Expert 2: 18.95%, Expert 3: 21.72%, Expert 4: 18.60%\n",
      "2024-10-22 09:24:50,587 - INFO - MoE Layer 3 Usage: Expert 0: 14.73%, Expert 1: 24.12%, Expert 2: 23.35%, Expert 3: 17.95%, Expert 4: 19.84%\n",
      "2024-10-22 09:24:50,589 - INFO - MoE Layer 4 Usage: Expert 0: 19.70%, Expert 1: 22.80%, Expert 2: 16.91%, Expert 3: 22.55%, Expert 4: 18.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:54,448 - INFO - MoE Layer 1 Usage: Expert 0: 21.10%, Expert 1: 19.02%, Expert 2: 19.66%, Expert 3: 20.15%, Expert 4: 20.06%\n",
      "2024-10-22 09:24:54,449 - INFO - MoE Layer 2 Usage: Expert 0: 20.55%, Expert 1: 19.31%, Expert 2: 19.33%, Expert 3: 21.87%, Expert 4: 18.94%\n",
      "2024-10-22 09:24:54,450 - INFO - MoE Layer 3 Usage: Expert 0: 14.52%, Expert 1: 24.45%, Expert 2: 23.14%, Expert 3: 18.58%, Expert 4: 19.32%\n",
      "2024-10-22 09:24:54,451 - INFO - MoE Layer 4 Usage: Expert 0: 19.36%, Expert 1: 21.30%, Expert 2: 18.24%, Expert 3: 23.42%, Expert 4: 17.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:24:58,304 - INFO - MoE Layer 1 Usage: Expert 0: 21.20%, Expert 1: 19.11%, Expert 2: 18.71%, Expert 3: 20.63%, Expert 4: 20.35%\n",
      "2024-10-22 09:24:58,304 - INFO - MoE Layer 2 Usage: Expert 0: 20.70%, Expert 1: 19.18%, Expert 2: 19.78%, Expert 3: 21.93%, Expert 4: 18.42%\n",
      "2024-10-22 09:24:58,305 - INFO - MoE Layer 3 Usage: Expert 0: 15.33%, Expert 1: 23.38%, Expert 2: 24.38%, Expert 3: 17.34%, Expert 4: 19.58%\n",
      "2024-10-22 09:24:58,307 - INFO - MoE Layer 4 Usage: Expert 0: 19.63%, Expert 1: 21.57%, Expert 2: 17.88%, Expert 3: 22.90%, Expert 4: 18.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:02,139 - INFO - MoE Layer 1 Usage: Expert 0: 21.13%, Expert 1: 18.98%, Expert 2: 19.08%, Expert 3: 20.43%, Expert 4: 20.38%\n",
      "2024-10-22 09:25:02,140 - INFO - MoE Layer 2 Usage: Expert 0: 20.70%, Expert 1: 19.74%, Expert 2: 18.68%, Expert 3: 22.04%, Expert 4: 18.84%\n",
      "2024-10-22 09:25:02,140 - INFO - MoE Layer 3 Usage: Expert 0: 14.43%, Expert 1: 23.97%, Expert 2: 23.78%, Expert 3: 18.06%, Expert 4: 19.75%\n",
      "2024-10-22 09:25:02,142 - INFO - MoE Layer 4 Usage: Expert 0: 20.61%, Expert 1: 20.70%, Expert 2: 18.10%, Expert 3: 22.81%, Expert 4: 17.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:05,995 - INFO - MoE Layer 1 Usage: Expert 0: 21.00%, Expert 1: 18.79%, Expert 2: 19.39%, Expert 3: 20.59%, Expert 4: 20.23%\n",
      "2024-10-22 09:25:05,996 - INFO - MoE Layer 2 Usage: Expert 0: 20.46%, Expert 1: 19.91%, Expert 2: 19.26%, Expert 3: 21.86%, Expert 4: 18.51%\n",
      "2024-10-22 09:25:05,997 - INFO - MoE Layer 3 Usage: Expert 0: 14.43%, Expert 1: 23.92%, Expert 2: 23.38%, Expert 3: 18.33%, Expert 4: 19.95%\n",
      "2024-10-22 09:25:05,999 - INFO - MoE Layer 4 Usage: Expert 0: 20.61%, Expert 1: 21.02%, Expert 2: 17.80%, Expert 3: 23.46%, Expert 4: 17.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:09,851 - INFO - MoE Layer 1 Usage: Expert 0: 20.99%, Expert 1: 18.93%, Expert 2: 19.19%, Expert 3: 20.70%, Expert 4: 20.19%\n",
      "2024-10-22 09:25:09,852 - INFO - MoE Layer 2 Usage: Expert 0: 20.21%, Expert 1: 19.67%, Expert 2: 19.69%, Expert 3: 21.61%, Expert 4: 18.81%\n",
      "2024-10-22 09:25:09,853 - INFO - MoE Layer 3 Usage: Expert 0: 14.74%, Expert 1: 24.27%, Expert 2: 23.44%, Expert 3: 18.32%, Expert 4: 19.22%\n",
      "2024-10-22 09:25:09,854 - INFO - MoE Layer 4 Usage: Expert 0: 20.30%, Expert 1: 21.29%, Expert 2: 17.51%, Expert 3: 23.39%, Expert 4: 17.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:13,685 - INFO - MoE Layer 1 Usage: Expert 0: 20.90%, Expert 1: 19.06%, Expert 2: 19.19%, Expert 3: 20.59%, Expert 4: 20.26%\n",
      "2024-10-22 09:25:13,686 - INFO - MoE Layer 2 Usage: Expert 0: 20.61%, Expert 1: 19.47%, Expert 2: 19.47%, Expert 3: 21.73%, Expert 4: 18.72%\n",
      "2024-10-22 09:25:13,687 - INFO - MoE Layer 3 Usage: Expert 0: 15.16%, Expert 1: 23.80%, Expert 2: 23.60%, Expert 3: 17.86%, Expert 4: 19.58%\n",
      "2024-10-22 09:25:13,688 - INFO - MoE Layer 4 Usage: Expert 0: 21.46%, Expert 1: 21.63%, Expert 2: 17.08%, Expert 3: 23.06%, Expert 4: 16.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:17,563 - INFO - MoE Layer 1 Usage: Expert 0: 21.18%, Expert 1: 18.68%, Expert 2: 19.27%, Expert 3: 20.52%, Expert 4: 20.36%\n",
      "2024-10-22 09:25:17,564 - INFO - MoE Layer 2 Usage: Expert 0: 20.42%, Expert 1: 19.58%, Expert 2: 19.72%, Expert 3: 21.30%, Expert 4: 18.98%\n",
      "2024-10-22 09:25:17,565 - INFO - MoE Layer 3 Usage: Expert 0: 14.59%, Expert 1: 23.72%, Expert 2: 23.78%, Expert 3: 18.34%, Expert 4: 19.57%\n",
      "2024-10-22 09:25:17,567 - INFO - MoE Layer 4 Usage: Expert 0: 21.87%, Expert 1: 20.99%, Expert 2: 17.27%, Expert 3: 23.48%, Expert 4: 16.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:21,390 - INFO - MoE Layer 1 Usage: Expert 0: 21.24%, Expert 1: 18.99%, Expert 2: 19.02%, Expert 3: 20.56%, Expert 4: 20.19%\n",
      "2024-10-22 09:25:21,391 - INFO - MoE Layer 2 Usage: Expert 0: 20.31%, Expert 1: 20.02%, Expert 2: 19.51%, Expert 3: 21.30%, Expert 4: 18.86%\n",
      "2024-10-22 09:25:21,392 - INFO - MoE Layer 3 Usage: Expert 0: 15.17%, Expert 1: 23.53%, Expert 2: 23.89%, Expert 3: 18.12%, Expert 4: 19.28%\n",
      "2024-10-22 09:25:21,394 - INFO - MoE Layer 4 Usage: Expert 0: 21.76%, Expert 1: 20.68%, Expert 2: 17.62%, Expert 3: 23.74%, Expert 4: 16.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:25,236 - INFO - MoE Layer 1 Usage: Expert 0: 20.76%, Expert 1: 18.85%, Expert 2: 19.24%, Expert 3: 20.74%, Expert 4: 20.41%\n",
      "2024-10-22 09:25:25,237 - INFO - MoE Layer 2 Usage: Expert 0: 20.01%, Expert 1: 19.70%, Expert 2: 19.75%, Expert 3: 21.92%, Expert 4: 18.62%\n",
      "2024-10-22 09:25:25,238 - INFO - MoE Layer 3 Usage: Expert 0: 15.45%, Expert 1: 24.17%, Expert 2: 23.18%, Expert 3: 17.87%, Expert 4: 19.33%\n",
      "2024-10-22 09:25:25,239 - INFO - MoE Layer 4 Usage: Expert 0: 21.64%, Expert 1: 20.95%, Expert 2: 17.09%, Expert 3: 24.12%, Expert 4: 16.20%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977f1540fb3842a49b0fd71e63879cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-500\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-500\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-500\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-500\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-500\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.058013439178467, 'eval_runtime': 0.5081, 'eval_samples_per_second': 1967.984, 'eval_steps_per_second': 66.911, 'epoch': 63.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-300] due to args.save_total_limit\n",
      "2024-10-22 09:25:29,897 - INFO - MoE Layer 1 Usage: Expert 0: 21.22%, Expert 1: 19.11%, Expert 2: 19.25%, Expert 3: 20.11%, Expert 4: 20.30%\n",
      "2024-10-22 09:25:29,898 - INFO - MoE Layer 2 Usage: Expert 0: 20.23%, Expert 1: 20.19%, Expert 2: 19.30%, Expert 3: 21.63%, Expert 4: 18.66%\n",
      "2024-10-22 09:25:29,899 - INFO - MoE Layer 3 Usage: Expert 0: 15.36%, Expert 1: 24.05%, Expert 2: 23.51%, Expert 3: 18.75%, Expert 4: 18.33%\n",
      "2024-10-22 09:25:29,900 - INFO - MoE Layer 4 Usage: Expert 0: 21.33%, Expert 1: 21.11%, Expert 2: 17.16%, Expert 3: 24.16%, Expert 4: 16.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:33,744 - INFO - MoE Layer 1 Usage: Expert 0: 20.96%, Expert 1: 18.85%, Expert 2: 19.08%, Expert 3: 20.94%, Expert 4: 20.16%\n",
      "2024-10-22 09:25:33,745 - INFO - MoE Layer 2 Usage: Expert 0: 20.01%, Expert 1: 19.99%, Expert 2: 19.64%, Expert 3: 21.79%, Expert 4: 18.57%\n",
      "2024-10-22 09:25:33,746 - INFO - MoE Layer 3 Usage: Expert 0: 15.53%, Expert 1: 23.66%, Expert 2: 23.06%, Expert 3: 18.19%, Expert 4: 19.56%\n",
      "2024-10-22 09:25:33,747 - INFO - MoE Layer 4 Usage: Expert 0: 21.98%, Expert 1: 20.53%, Expert 2: 17.30%, Expert 3: 24.47%, Expert 4: 15.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:37,553 - INFO - MoE Layer 1 Usage: Expert 0: 21.05%, Expert 1: 18.86%, Expert 2: 19.24%, Expert 3: 20.30%, Expert 4: 20.54%\n",
      "2024-10-22 09:25:37,554 - INFO - MoE Layer 2 Usage: Expert 0: 20.41%, Expert 1: 20.26%, Expert 2: 19.43%, Expert 3: 21.14%, Expert 4: 18.76%\n",
      "2024-10-22 09:25:37,555 - INFO - MoE Layer 3 Usage: Expert 0: 15.63%, Expert 1: 22.72%, Expert 2: 24.21%, Expert 3: 18.16%, Expert 4: 19.27%\n",
      "2024-10-22 09:25:37,556 - INFO - MoE Layer 4 Usage: Expert 0: 22.82%, Expert 1: 20.57%, Expert 2: 16.81%, Expert 3: 24.48%, Expert 4: 15.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:41,375 - INFO - MoE Layer 1 Usage: Expert 0: 21.00%, Expert 1: 19.04%, Expert 2: 18.89%, Expert 3: 20.86%, Expert 4: 20.21%\n",
      "2024-10-22 09:25:41,376 - INFO - MoE Layer 2 Usage: Expert 0: 19.95%, Expert 1: 19.93%, Expert 2: 19.73%, Expert 3: 21.69%, Expert 4: 18.70%\n",
      "2024-10-22 09:25:41,377 - INFO - MoE Layer 3 Usage: Expert 0: 15.45%, Expert 1: 23.81%, Expert 2: 23.15%, Expert 3: 18.31%, Expert 4: 19.28%\n",
      "2024-10-22 09:25:41,378 - INFO - MoE Layer 4 Usage: Expert 0: 22.79%, Expert 1: 20.45%, Expert 2: 16.74%, Expert 3: 24.57%, Expert 4: 15.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:45,201 - INFO - MoE Layer 1 Usage: Expert 0: 20.63%, Expert 1: 19.12%, Expert 2: 19.14%, Expert 3: 20.74%, Expert 4: 20.37%\n",
      "2024-10-22 09:25:45,202 - INFO - MoE Layer 2 Usage: Expert 0: 19.96%, Expert 1: 19.94%, Expert 2: 19.49%, Expert 3: 21.72%, Expert 4: 18.88%\n",
      "2024-10-22 09:25:45,203 - INFO - MoE Layer 3 Usage: Expert 0: 15.90%, Expert 1: 23.17%, Expert 2: 24.02%, Expert 3: 17.92%, Expert 4: 18.99%\n",
      "2024-10-22 09:25:45,204 - INFO - MoE Layer 4 Usage: Expert 0: 23.02%, Expert 1: 20.29%, Expert 2: 16.82%, Expert 3: 24.79%, Expert 4: 15.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:49,018 - INFO - MoE Layer 1 Usage: Expert 0: 21.27%, Expert 1: 18.71%, Expert 2: 19.04%, Expert 3: 20.89%, Expert 4: 20.09%\n",
      "2024-10-22 09:25:49,019 - INFO - MoE Layer 2 Usage: Expert 0: 19.89%, Expert 1: 20.24%, Expert 2: 19.42%, Expert 3: 21.59%, Expert 4: 18.87%\n",
      "2024-10-22 09:25:49,020 - INFO - MoE Layer 3 Usage: Expert 0: 15.49%, Expert 1: 23.52%, Expert 2: 23.72%, Expert 3: 18.29%, Expert 4: 18.99%\n",
      "2024-10-22 09:25:49,021 - INFO - MoE Layer 4 Usage: Expert 0: 23.07%, Expert 1: 20.32%, Expert 2: 17.02%, Expert 3: 24.83%, Expert 4: 14.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:52,859 - INFO - MoE Layer 1 Usage: Expert 0: 21.05%, Expert 1: 18.84%, Expert 2: 19.16%, Expert 3: 20.66%, Expert 4: 20.29%\n",
      "2024-10-22 09:25:52,860 - INFO - MoE Layer 2 Usage: Expert 0: 20.22%, Expert 1: 19.91%, Expert 2: 19.56%, Expert 3: 21.67%, Expert 4: 18.63%\n",
      "2024-10-22 09:25:52,861 - INFO - MoE Layer 3 Usage: Expert 0: 15.79%, Expert 1: 23.30%, Expert 2: 23.52%, Expert 3: 18.25%, Expert 4: 19.14%\n",
      "2024-10-22 09:25:52,862 - INFO - MoE Layer 4 Usage: Expert 0: 23.57%, Expert 1: 20.00%, Expert 2: 16.89%, Expert 3: 24.78%, Expert 4: 14.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:25:56,668 - INFO - MoE Layer 1 Usage: Expert 0: 20.96%, Expert 1: 18.98%, Expert 2: 18.91%, Expert 3: 20.77%, Expert 4: 20.38%\n",
      "2024-10-22 09:25:56,669 - INFO - MoE Layer 2 Usage: Expert 0: 19.90%, Expert 1: 20.22%, Expert 2: 19.64%, Expert 3: 21.47%, Expert 4: 18.76%\n",
      "2024-10-22 09:25:56,670 - INFO - MoE Layer 3 Usage: Expert 0: 15.80%, Expert 1: 23.11%, Expert 2: 23.73%, Expert 3: 18.50%, Expert 4: 18.85%\n",
      "2024-10-22 09:25:56,671 - INFO - MoE Layer 4 Usage: Expert 0: 23.25%, Expert 1: 19.60%, Expert 2: 16.99%, Expert 3: 25.42%, Expert 4: 14.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:00,481 - INFO - MoE Layer 1 Usage: Expert 0: 21.18%, Expert 1: 18.54%, Expert 2: 18.86%, Expert 3: 20.79%, Expert 4: 20.64%\n",
      "2024-10-22 09:26:00,482 - INFO - MoE Layer 2 Usage: Expert 0: 19.76%, Expert 1: 20.33%, Expert 2: 19.41%, Expert 3: 21.70%, Expert 4: 18.80%\n",
      "2024-10-22 09:26:00,483 - INFO - MoE Layer 3 Usage: Expert 0: 16.36%, Expert 1: 22.93%, Expert 2: 23.46%, Expert 3: 18.34%, Expert 4: 18.91%\n",
      "2024-10-22 09:26:00,485 - INFO - MoE Layer 4 Usage: Expert 0: 23.68%, Expert 1: 20.09%, Expert 2: 16.89%, Expert 3: 25.23%, Expert 4: 14.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:04,358 - INFO - MoE Layer 1 Usage: Expert 0: 20.91%, Expert 1: 18.96%, Expert 2: 18.92%, Expert 3: 21.05%, Expert 4: 20.16%\n",
      "2024-10-22 09:26:04,359 - INFO - MoE Layer 2 Usage: Expert 0: 19.91%, Expert 1: 20.03%, Expert 2: 19.64%, Expert 3: 21.44%, Expert 4: 18.98%\n",
      "2024-10-22 09:26:04,360 - INFO - MoE Layer 3 Usage: Expert 0: 16.50%, Expert 1: 22.80%, Expert 2: 23.65%, Expert 3: 18.11%, Expert 4: 18.93%\n",
      "2024-10-22 09:26:04,361 - INFO - MoE Layer 4 Usage: Expert 0: 23.30%, Expert 1: 19.84%, Expert 2: 17.42%, Expert 3: 25.10%, Expert 4: 14.33%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609f479570c4431abb0de5688d636b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-600\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-600\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-600\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-600\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-600\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-600\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.03071403503418, 'eval_runtime': 0.5095, 'eval_samples_per_second': 1962.55, 'eval_steps_per_second': 66.727, 'epoch': 75.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-400] due to args.save_total_limit\n",
      "2024-10-22 09:26:09,013 - INFO - MoE Layer 1 Usage: Expert 0: 21.03%, Expert 1: 18.88%, Expert 2: 18.98%, Expert 3: 20.57%, Expert 4: 20.54%\n",
      "2024-10-22 09:26:09,015 - INFO - MoE Layer 2 Usage: Expert 0: 19.75%, Expert 1: 20.14%, Expert 2: 19.27%, Expert 3: 22.09%, Expert 4: 18.75%\n",
      "2024-10-22 09:26:09,017 - INFO - MoE Layer 3 Usage: Expert 0: 16.07%, Expert 1: 23.35%, Expert 2: 23.24%, Expert 3: 19.05%, Expert 4: 18.30%\n",
      "2024-10-22 09:26:09,018 - INFO - MoE Layer 4 Usage: Expert 0: 23.46%, Expert 1: 19.73%, Expert 2: 16.85%, Expert 3: 25.01%, Expert 4: 14.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:12,905 - INFO - MoE Layer 1 Usage: Expert 0: 21.19%, Expert 1: 18.53%, Expert 2: 19.03%, Expert 3: 20.85%, Expert 4: 20.40%\n",
      "2024-10-22 09:26:12,906 - INFO - MoE Layer 2 Usage: Expert 0: 19.87%, Expert 1: 20.10%, Expert 2: 19.68%, Expert 3: 21.65%, Expert 4: 18.70%\n",
      "2024-10-22 09:26:12,907 - INFO - MoE Layer 3 Usage: Expert 0: 16.12%, Expert 1: 22.92%, Expert 2: 23.22%, Expert 3: 18.71%, Expert 4: 19.04%\n",
      "2024-10-22 09:26:12,908 - INFO - MoE Layer 4 Usage: Expert 0: 23.66%, Expert 1: 20.06%, Expert 2: 17.11%, Expert 3: 24.89%, Expert 4: 14.28%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:16,731 - INFO - MoE Layer 1 Usage: Expert 0: 20.90%, Expert 1: 18.55%, Expert 2: 18.97%, Expert 3: 21.01%, Expert 4: 20.57%\n",
      "2024-10-22 09:26:16,732 - INFO - MoE Layer 2 Usage: Expert 0: 20.18%, Expert 1: 19.94%, Expert 2: 19.32%, Expert 3: 21.51%, Expert 4: 19.06%\n",
      "2024-10-22 09:26:16,733 - INFO - MoE Layer 3 Usage: Expert 0: 16.43%, Expert 1: 23.17%, Expert 2: 22.94%, Expert 3: 18.74%, Expert 4: 18.72%\n",
      "2024-10-22 09:26:16,735 - INFO - MoE Layer 4 Usage: Expert 0: 23.47%, Expert 1: 19.92%, Expert 2: 17.36%, Expert 3: 25.13%, Expert 4: 14.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:20,578 - INFO - MoE Layer 1 Usage: Expert 0: 20.79%, Expert 1: 18.83%, Expert 2: 18.89%, Expert 3: 21.09%, Expert 4: 20.39%\n",
      "2024-10-22 09:26:20,579 - INFO - MoE Layer 2 Usage: Expert 0: 19.88%, Expert 1: 19.94%, Expert 2: 19.52%, Expert 3: 21.70%, Expert 4: 18.96%\n",
      "2024-10-22 09:26:20,580 - INFO - MoE Layer 3 Usage: Expert 0: 16.49%, Expert 1: 23.17%, Expert 2: 22.99%, Expert 3: 18.92%, Expert 4: 18.44%\n",
      "2024-10-22 09:26:20,581 - INFO - MoE Layer 4 Usage: Expert 0: 23.29%, Expert 1: 19.84%, Expert 2: 17.44%, Expert 3: 25.13%, Expert 4: 14.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:24,443 - INFO - MoE Layer 1 Usage: Expert 0: 21.05%, Expert 1: 18.78%, Expert 2: 18.86%, Expert 3: 20.99%, Expert 4: 20.32%\n",
      "2024-10-22 09:26:24,444 - INFO - MoE Layer 2 Usage: Expert 0: 20.16%, Expert 1: 20.13%, Expert 2: 19.52%, Expert 3: 21.40%, Expert 4: 18.79%\n",
      "2024-10-22 09:26:24,444 - INFO - MoE Layer 3 Usage: Expert 0: 16.39%, Expert 1: 22.50%, Expert 2: 22.79%, Expert 3: 19.02%, Expert 4: 19.30%\n",
      "2024-10-22 09:26:24,446 - INFO - MoE Layer 4 Usage: Expert 0: 23.64%, Expert 1: 19.58%, Expert 2: 17.57%, Expert 3: 25.04%, Expert 4: 14.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:28,297 - INFO - MoE Layer 1 Usage: Expert 0: 20.71%, Expert 1: 18.91%, Expert 2: 18.84%, Expert 3: 21.10%, Expert 4: 20.44%\n",
      "2024-10-22 09:26:28,299 - INFO - MoE Layer 2 Usage: Expert 0: 19.84%, Expert 1: 19.99%, Expert 2: 19.63%, Expert 3: 21.84%, Expert 4: 18.70%\n",
      "2024-10-22 09:26:28,300 - INFO - MoE Layer 3 Usage: Expert 0: 16.51%, Expert 1: 22.73%, Expert 2: 23.09%, Expert 3: 18.86%, Expert 4: 18.81%\n",
      "2024-10-22 09:26:28,301 - INFO - MoE Layer 4 Usage: Expert 0: 23.34%, Expert 1: 19.56%, Expert 2: 17.72%, Expert 3: 25.21%, Expert 4: 14.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:32,118 - INFO - MoE Layer 1 Usage: Expert 0: 20.93%, Expert 1: 18.81%, Expert 2: 19.06%, Expert 3: 20.70%, Expert 4: 20.50%\n",
      "2024-10-22 09:26:32,119 - INFO - MoE Layer 2 Usage: Expert 0: 20.15%, Expert 1: 19.94%, Expert 2: 19.56%, Expert 3: 21.53%, Expert 4: 18.82%\n",
      "2024-10-22 09:26:32,120 - INFO - MoE Layer 3 Usage: Expert 0: 16.66%, Expert 1: 22.91%, Expert 2: 23.41%, Expert 3: 18.66%, Expert 4: 18.37%\n",
      "2024-10-22 09:26:32,121 - INFO - MoE Layer 4 Usage: Expert 0: 23.28%, Expert 1: 19.59%, Expert 2: 17.65%, Expert 3: 25.30%, Expert 4: 14.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:35,943 - INFO - MoE Layer 1 Usage: Expert 0: 21.13%, Expert 1: 18.69%, Expert 2: 18.80%, Expert 3: 20.93%, Expert 4: 20.44%\n",
      "2024-10-22 09:26:35,944 - INFO - MoE Layer 2 Usage: Expert 0: 19.69%, Expert 1: 20.13%, Expert 2: 19.53%, Expert 3: 21.54%, Expert 4: 19.12%\n",
      "2024-10-22 09:26:35,945 - INFO - MoE Layer 3 Usage: Expert 0: 16.59%, Expert 1: 22.75%, Expert 2: 23.31%, Expert 3: 18.96%, Expert 4: 18.40%\n",
      "2024-10-22 09:26:35,946 - INFO - MoE Layer 4 Usage: Expert 0: 23.10%, Expert 1: 19.40%, Expert 2: 17.64%, Expert 3: 25.59%, Expert 4: 14.28%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:39,771 - INFO - MoE Layer 1 Usage: Expert 0: 20.93%, Expert 1: 18.72%, Expert 2: 18.77%, Expert 3: 21.14%, Expert 4: 20.43%\n",
      "2024-10-22 09:26:39,772 - INFO - MoE Layer 2 Usage: Expert 0: 19.98%, Expert 1: 19.83%, Expert 2: 19.60%, Expert 3: 21.64%, Expert 4: 18.94%\n",
      "2024-10-22 09:26:39,773 - INFO - MoE Layer 3 Usage: Expert 0: 16.73%, Expert 1: 22.46%, Expert 2: 23.13%, Expert 3: 18.93%, Expert 4: 18.75%\n",
      "2024-10-22 09:26:39,775 - INFO - MoE Layer 4 Usage: Expert 0: 23.12%, Expert 1: 19.72%, Expert 2: 18.11%, Expert 3: 24.78%, Expert 4: 14.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:43,612 - INFO - MoE Layer 1 Usage: Expert 0: 20.88%, Expert 1: 18.73%, Expert 2: 18.86%, Expert 3: 20.97%, Expert 4: 20.56%\n",
      "2024-10-22 09:26:43,613 - INFO - MoE Layer 2 Usage: Expert 0: 19.95%, Expert 1: 19.79%, Expert 2: 19.53%, Expert 3: 21.62%, Expert 4: 19.11%\n",
      "2024-10-22 09:26:43,614 - INFO - MoE Layer 3 Usage: Expert 0: 16.82%, Expert 1: 22.71%, Expert 2: 22.62%, Expert 3: 18.96%, Expert 4: 18.88%\n",
      "2024-10-22 09:26:43,615 - INFO - MoE Layer 4 Usage: Expert 0: 23.52%, Expert 1: 19.81%, Expert 2: 17.87%, Expert 3: 24.76%, Expert 4: 14.03%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799c0b6d0fa64ebaaf88c37ec6fef738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-700\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-700\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-700\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-700\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-700\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-700\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.148586750030518, 'eval_runtime': 0.5136, 'eval_samples_per_second': 1947.177, 'eval_steps_per_second': 66.204, 'epoch': 88.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-500] due to args.save_total_limit\n",
      "2024-10-22 09:26:48,274 - INFO - MoE Layer 1 Usage: Expert 0: 21.00%, Expert 1: 18.87%, Expert 2: 18.81%, Expert 3: 20.80%, Expert 4: 20.52%\n",
      "2024-10-22 09:26:48,275 - INFO - MoE Layer 2 Usage: Expert 0: 19.91%, Expert 1: 20.16%, Expert 2: 19.62%, Expert 3: 21.61%, Expert 4: 18.70%\n",
      "2024-10-22 09:26:48,275 - INFO - MoE Layer 3 Usage: Expert 0: 16.32%, Expert 1: 23.00%, Expert 2: 22.61%, Expert 3: 19.88%, Expert 4: 18.18%\n",
      "2024-10-22 09:26:48,277 - INFO - MoE Layer 4 Usage: Expert 0: 23.09%, Expert 1: 19.43%, Expert 2: 18.07%, Expert 3: 25.26%, Expert 4: 14.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:52,174 - INFO - MoE Layer 1 Usage: Expert 0: 20.74%, Expert 1: 18.86%, Expert 2: 18.84%, Expert 3: 20.94%, Expert 4: 20.62%\n",
      "2024-10-22 09:26:52,175 - INFO - MoE Layer 2 Usage: Expert 0: 20.10%, Expert 1: 20.01%, Expert 2: 19.39%, Expert 3: 21.38%, Expert 4: 19.12%\n",
      "2024-10-22 09:26:52,176 - INFO - MoE Layer 3 Usage: Expert 0: 16.62%, Expert 1: 22.29%, Expert 2: 22.99%, Expert 3: 19.45%, Expert 4: 18.64%\n",
      "2024-10-22 09:26:52,178 - INFO - MoE Layer 4 Usage: Expert 0: 22.87%, Expert 1: 19.19%, Expert 2: 18.17%, Expert 3: 25.45%, Expert 4: 14.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:26:56,207 - INFO - MoE Layer 1 Usage: Expert 0: 20.95%, Expert 1: 18.82%, Expert 2: 18.51%, Expert 3: 21.29%, Expert 4: 20.42%\n",
      "2024-10-22 09:26:56,208 - INFO - MoE Layer 2 Usage: Expert 0: 19.99%, Expert 1: 19.76%, Expert 2: 19.62%, Expert 3: 21.59%, Expert 4: 19.04%\n",
      "2024-10-22 09:26:56,209 - INFO - MoE Layer 3 Usage: Expert 0: 16.90%, Expert 1: 22.62%, Expert 2: 23.03%, Expert 3: 18.79%, Expert 4: 18.67%\n",
      "2024-10-22 09:26:56,210 - INFO - MoE Layer 4 Usage: Expert 0: 22.71%, Expert 1: 19.66%, Expert 2: 18.22%, Expert 3: 24.99%, Expert 4: 14.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:00,044 - INFO - MoE Layer 1 Usage: Expert 0: 20.88%, Expert 1: 18.99%, Expert 2: 18.84%, Expert 3: 20.73%, Expert 4: 20.56%\n",
      "2024-10-22 09:27:00,045 - INFO - MoE Layer 2 Usage: Expert 0: 20.03%, Expert 1: 19.63%, Expert 2: 19.73%, Expert 3: 21.70%, Expert 4: 18.91%\n",
      "2024-10-22 09:27:00,046 - INFO - MoE Layer 3 Usage: Expert 0: 16.92%, Expert 1: 22.63%, Expert 2: 22.55%, Expert 3: 19.36%, Expert 4: 18.54%\n",
      "2024-10-22 09:27:00,047 - INFO - MoE Layer 4 Usage: Expert 0: 22.82%, Expert 1: 19.58%, Expert 2: 18.26%, Expert 3: 25.19%, Expert 4: 14.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:03,893 - INFO - MoE Layer 1 Usage: Expert 0: 21.26%, Expert 1: 18.77%, Expert 2: 18.81%, Expert 3: 21.02%, Expert 4: 20.15%\n",
      "2024-10-22 09:27:03,894 - INFO - MoE Layer 2 Usage: Expert 0: 19.73%, Expert 1: 19.85%, Expert 2: 19.75%, Expert 3: 21.61%, Expert 4: 19.06%\n",
      "2024-10-22 09:27:03,894 - INFO - MoE Layer 3 Usage: Expert 0: 16.75%, Expert 1: 22.25%, Expert 2: 22.85%, Expert 3: 19.63%, Expert 4: 18.53%\n",
      "2024-10-22 09:27:03,896 - INFO - MoE Layer 4 Usage: Expert 0: 22.93%, Expert 1: 19.56%, Expert 2: 18.12%, Expert 3: 25.04%, Expert 4: 14.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:07,735 - INFO - MoE Layer 1 Usage: Expert 0: 20.79%, Expert 1: 18.75%, Expert 2: 19.05%, Expert 3: 20.92%, Expert 4: 20.48%\n",
      "2024-10-22 09:27:07,736 - INFO - MoE Layer 2 Usage: Expert 0: 20.11%, Expert 1: 19.68%, Expert 2: 19.73%, Expert 3: 21.40%, Expert 4: 19.08%\n",
      "2024-10-22 09:27:07,737 - INFO - MoE Layer 3 Usage: Expert 0: 16.78%, Expert 1: 22.75%, Expert 2: 22.73%, Expert 3: 19.18%, Expert 4: 18.56%\n",
      "2024-10-22 09:27:07,738 - INFO - MoE Layer 4 Usage: Expert 0: 23.20%, Expert 1: 19.60%, Expert 2: 18.43%, Expert 3: 24.51%, Expert 4: 14.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:11,636 - INFO - MoE Layer 1 Usage: Expert 0: 21.05%, Expert 1: 18.66%, Expert 2: 18.65%, Expert 3: 21.11%, Expert 4: 20.53%\n",
      "2024-10-22 09:27:11,637 - INFO - MoE Layer 2 Usage: Expert 0: 20.07%, Expert 1: 19.91%, Expert 2: 19.28%, Expert 3: 21.71%, Expert 4: 19.03%\n",
      "2024-10-22 09:27:11,638 - INFO - MoE Layer 3 Usage: Expert 0: 16.62%, Expert 1: 22.54%, Expert 2: 22.58%, Expert 3: 19.27%, Expert 4: 18.99%\n",
      "2024-10-22 09:27:11,639 - INFO - MoE Layer 4 Usage: Expert 0: 22.81%, Expert 1: 19.60%, Expert 2: 18.62%, Expert 3: 24.82%, Expert 4: 14.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:15,538 - INFO - MoE Layer 1 Usage: Expert 0: 21.10%, Expert 1: 18.87%, Expert 2: 18.65%, Expert 3: 21.08%, Expert 4: 20.30%\n",
      "2024-10-22 09:27:15,539 - INFO - MoE Layer 2 Usage: Expert 0: 19.84%, Expert 1: 19.87%, Expert 2: 19.63%, Expert 3: 21.64%, Expert 4: 19.02%\n",
      "2024-10-22 09:27:15,541 - INFO - MoE Layer 3 Usage: Expert 0: 16.69%, Expert 1: 22.38%, Expert 2: 22.62%, Expert 3: 19.72%, Expert 4: 18.60%\n",
      "2024-10-22 09:27:15,542 - INFO - MoE Layer 4 Usage: Expert 0: 22.63%, Expert 1: 19.73%, Expert 2: 18.53%, Expert 3: 24.65%, Expert 4: 14.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:19,448 - INFO - MoE Layer 1 Usage: Expert 0: 20.92%, Expert 1: 18.84%, Expert 2: 18.76%, Expert 3: 21.04%, Expert 4: 20.44%\n",
      "2024-10-22 09:27:19,449 - INFO - MoE Layer 2 Usage: Expert 0: 20.28%, Expert 1: 19.71%, Expert 2: 19.53%, Expert 3: 21.63%, Expert 4: 18.85%\n",
      "2024-10-22 09:27:19,449 - INFO - MoE Layer 3 Usage: Expert 0: 16.83%, Expert 1: 22.82%, Expert 2: 22.15%, Expert 3: 19.39%, Expert 4: 18.81%\n",
      "2024-10-22 09:27:19,451 - INFO - MoE Layer 4 Usage: Expert 0: 22.48%, Expert 1: 19.23%, Expert 2: 18.82%, Expert 3: 25.17%, Expert 4: 14.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:23,359 - INFO - MoE Layer 1 Usage: Expert 0: 21.21%, Expert 1: 18.73%, Expert 2: 18.74%, Expert 3: 21.08%, Expert 4: 20.24%\n",
      "2024-10-22 09:27:23,360 - INFO - MoE Layer 2 Usage: Expert 0: 19.87%, Expert 1: 20.13%, Expert 2: 19.27%, Expert 3: 21.64%, Expert 4: 19.09%\n",
      "2024-10-22 09:27:23,362 - INFO - MoE Layer 3 Usage: Expert 0: 16.74%, Expert 1: 22.45%, Expert 2: 22.73%, Expert 3: 19.61%, Expert 4: 18.48%\n",
      "2024-10-22 09:27:23,364 - INFO - MoE Layer 4 Usage: Expert 0: 22.88%, Expert 1: 19.97%, Expert 2: 18.44%, Expert 3: 24.51%, Expert 4: 14.19%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecf8def2d624adf927e8397517a7564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-800\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-800\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-800\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-800\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-800\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-800\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.366456031799316, 'eval_runtime': 0.5504, 'eval_samples_per_second': 1816.728, 'eval_steps_per_second': 61.769, 'epoch': 101.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-700] due to args.save_total_limit\n",
      "2024-10-22 09:27:28,182 - INFO - MoE Layer 1 Usage: Expert 0: 20.90%, Expert 1: 18.71%, Expert 2: 18.83%, Expert 3: 21.06%, Expert 4: 20.50%\n",
      "2024-10-22 09:27:28,183 - INFO - MoE Layer 2 Usage: Expert 0: 19.65%, Expert 1: 19.78%, Expert 2: 19.42%, Expert 3: 21.97%, Expert 4: 19.18%\n",
      "2024-10-22 09:27:28,184 - INFO - MoE Layer 3 Usage: Expert 0: 16.43%, Expert 1: 23.03%, Expert 2: 22.43%, Expert 3: 19.96%, Expert 4: 18.14%\n",
      "2024-10-22 09:27:28,186 - INFO - MoE Layer 4 Usage: Expert 0: 22.06%, Expert 1: 20.01%, Expert 2: 18.64%, Expert 3: 24.72%, Expert 4: 14.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:32,109 - INFO - MoE Layer 1 Usage: Expert 0: 21.19%, Expert 1: 18.92%, Expert 2: 18.65%, Expert 3: 21.01%, Expert 4: 20.23%\n",
      "2024-10-22 09:27:32,110 - INFO - MoE Layer 2 Usage: Expert 0: 20.30%, Expert 1: 19.62%, Expert 2: 19.36%, Expert 3: 21.68%, Expert 4: 19.04%\n",
      "2024-10-22 09:27:32,111 - INFO - MoE Layer 3 Usage: Expert 0: 16.61%, Expert 1: 22.23%, Expert 2: 22.70%, Expert 3: 19.36%, Expert 4: 19.09%\n",
      "2024-10-22 09:27:32,112 - INFO - MoE Layer 4 Usage: Expert 0: 22.38%, Expert 1: 19.81%, Expert 2: 18.99%, Expert 3: 24.69%, Expert 4: 14.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:36,026 - INFO - MoE Layer 1 Usage: Expert 0: 20.91%, Expert 1: 18.89%, Expert 2: 18.64%, Expert 3: 21.31%, Expert 4: 20.25%\n",
      "2024-10-22 09:27:36,027 - INFO - MoE Layer 2 Usage: Expert 0: 19.88%, Expert 1: 19.90%, Expert 2: 19.47%, Expert 3: 21.73%, Expert 4: 19.01%\n",
      "2024-10-22 09:27:36,028 - INFO - MoE Layer 3 Usage: Expert 0: 16.51%, Expert 1: 22.51%, Expert 2: 22.64%, Expert 3: 19.52%, Expert 4: 18.82%\n",
      "2024-10-22 09:27:36,029 - INFO - MoE Layer 4 Usage: Expert 0: 22.30%, Expert 1: 19.92%, Expert 2: 18.83%, Expert 3: 24.70%, Expert 4: 14.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:39,926 - INFO - MoE Layer 1 Usage: Expert 0: 20.95%, Expert 1: 18.97%, Expert 2: 18.73%, Expert 3: 21.03%, Expert 4: 20.33%\n",
      "2024-10-22 09:27:39,927 - INFO - MoE Layer 2 Usage: Expert 0: 20.11%, Expert 1: 19.84%, Expert 2: 19.30%, Expert 3: 21.71%, Expert 4: 19.05%\n",
      "2024-10-22 09:27:39,928 - INFO - MoE Layer 3 Usage: Expert 0: 16.73%, Expert 1: 22.50%, Expert 2: 22.48%, Expert 3: 19.57%, Expert 4: 18.72%\n",
      "2024-10-22 09:27:39,929 - INFO - MoE Layer 4 Usage: Expert 0: 22.36%, Expert 1: 19.86%, Expert 2: 18.97%, Expert 3: 24.54%, Expert 4: 14.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:43,854 - INFO - MoE Layer 1 Usage: Expert 0: 20.89%, Expert 1: 18.82%, Expert 2: 18.70%, Expert 3: 21.05%, Expert 4: 20.54%\n",
      "2024-10-22 09:27:43,855 - INFO - MoE Layer 2 Usage: Expert 0: 20.09%, Expert 1: 19.73%, Expert 2: 19.55%, Expert 3: 21.66%, Expert 4: 18.97%\n",
      "2024-10-22 09:27:43,856 - INFO - MoE Layer 3 Usage: Expert 0: 16.54%, Expert 1: 22.74%, Expert 2: 22.28%, Expert 3: 19.57%, Expert 4: 18.87%\n",
      "2024-10-22 09:27:43,857 - INFO - MoE Layer 4 Usage: Expert 0: 22.36%, Expert 1: 20.21%, Expert 2: 19.08%, Expert 3: 24.22%, Expert 4: 14.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:47,799 - INFO - MoE Layer 1 Usage: Expert 0: 20.86%, Expert 1: 18.77%, Expert 2: 18.69%, Expert 3: 21.39%, Expert 4: 20.28%\n",
      "2024-10-22 09:27:47,800 - INFO - MoE Layer 2 Usage: Expert 0: 19.93%, Expert 1: 19.78%, Expert 2: 19.62%, Expert 3: 21.53%, Expert 4: 19.14%\n",
      "2024-10-22 09:27:47,801 - INFO - MoE Layer 3 Usage: Expert 0: 16.38%, Expert 1: 22.36%, Expert 2: 22.67%, Expert 3: 19.70%, Expert 4: 18.89%\n",
      "2024-10-22 09:27:47,802 - INFO - MoE Layer 4 Usage: Expert 0: 22.25%, Expert 1: 20.22%, Expert 2: 18.96%, Expert 3: 24.49%, Expert 4: 14.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:51,673 - INFO - MoE Layer 1 Usage: Expert 0: 20.84%, Expert 1: 18.89%, Expert 2: 18.76%, Expert 3: 21.09%, Expert 4: 20.41%\n",
      "2024-10-22 09:27:51,674 - INFO - MoE Layer 2 Usage: Expert 0: 19.96%, Expert 1: 19.63%, Expert 2: 19.40%, Expert 3: 21.86%, Expert 4: 19.14%\n",
      "2024-10-22 09:27:51,675 - INFO - MoE Layer 3 Usage: Expert 0: 16.51%, Expert 1: 22.54%, Expert 2: 22.58%, Expert 3: 19.72%, Expert 4: 18.65%\n",
      "2024-10-22 09:27:51,676 - INFO - MoE Layer 4 Usage: Expert 0: 21.93%, Expert 1: 20.08%, Expert 2: 19.11%, Expert 3: 24.68%, Expert 4: 14.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:55,595 - INFO - MoE Layer 1 Usage: Expert 0: 21.13%, Expert 1: 18.62%, Expert 2: 18.66%, Expert 3: 21.08%, Expert 4: 20.51%\n",
      "2024-10-22 09:27:55,596 - INFO - MoE Layer 2 Usage: Expert 0: 20.04%, Expert 1: 19.88%, Expert 2: 19.46%, Expert 3: 21.69%, Expert 4: 18.94%\n",
      "2024-10-22 09:27:55,597 - INFO - MoE Layer 3 Usage: Expert 0: 16.55%, Expert 1: 22.36%, Expert 2: 22.59%, Expert 3: 19.58%, Expert 4: 18.92%\n",
      "2024-10-22 09:27:55,598 - INFO - MoE Layer 4 Usage: Expert 0: 21.95%, Expert 1: 20.21%, Expert 2: 19.19%, Expert 3: 24.66%, Expert 4: 13.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:27:59,487 - INFO - MoE Layer 1 Usage: Expert 0: 21.25%, Expert 1: 18.81%, Expert 2: 18.84%, Expert 3: 21.01%, Expert 4: 20.08%\n",
      "2024-10-22 09:27:59,488 - INFO - MoE Layer 2 Usage: Expert 0: 20.07%, Expert 1: 19.81%, Expert 2: 19.43%, Expert 3: 21.74%, Expert 4: 18.95%\n",
      "2024-10-22 09:27:59,489 - INFO - MoE Layer 3 Usage: Expert 0: 16.35%, Expert 1: 22.40%, Expert 2: 22.46%, Expert 3: 19.99%, Expert 4: 18.79%\n",
      "2024-10-22 09:27:59,490 - INFO - MoE Layer 4 Usage: Expert 0: 22.00%, Expert 1: 20.36%, Expert 2: 19.21%, Expert 3: 24.37%, Expert 4: 14.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:03,408 - INFO - MoE Layer 1 Usage: Expert 0: 21.02%, Expert 1: 18.74%, Expert 2: 18.61%, Expert 3: 21.14%, Expert 4: 20.49%\n",
      "2024-10-22 09:28:03,409 - INFO - MoE Layer 2 Usage: Expert 0: 20.16%, Expert 1: 19.47%, Expert 2: 19.63%, Expert 3: 21.72%, Expert 4: 19.01%\n",
      "2024-10-22 09:28:03,410 - INFO - MoE Layer 3 Usage: Expert 0: 16.56%, Expert 1: 22.73%, Expert 2: 22.28%, Expert 3: 19.61%, Expert 4: 18.83%\n",
      "2024-10-22 09:28:03,412 - INFO - MoE Layer 4 Usage: Expert 0: 21.71%, Expert 1: 20.36%, Expert 2: 19.17%, Expert 3: 24.81%, Expert 4: 13.96%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acca16fe660431e9ecde3c3ae748578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-900\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-900\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-900\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-900\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-900\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-900\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.569530010223389, 'eval_runtime': 0.5302, 'eval_samples_per_second': 1885.94, 'eval_steps_per_second': 64.122, 'epoch': 113.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-800] due to args.save_total_limit\n",
      "2024-10-22 09:28:08,172 - INFO - MoE Layer 1 Usage: Expert 0: 20.64%, Expert 1: 18.91%, Expert 2: 18.99%, Expert 3: 20.93%, Expert 4: 20.53%\n",
      "2024-10-22 09:28:08,173 - INFO - MoE Layer 2 Usage: Expert 0: 19.24%, Expert 1: 19.97%, Expert 2: 19.24%, Expert 3: 22.20%, Expert 4: 19.35%\n",
      "2024-10-22 09:28:08,174 - INFO - MoE Layer 3 Usage: Expert 0: 16.18%, Expert 1: 23.14%, Expert 2: 22.61%, Expert 3: 20.12%, Expert 4: 17.95%\n",
      "2024-10-22 09:28:08,175 - INFO - MoE Layer 4 Usage: Expert 0: 21.61%, Expert 1: 19.89%, Expert 2: 19.35%, Expert 3: 25.04%, Expert 4: 14.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:12,146 - INFO - MoE Layer 1 Usage: Expert 0: 20.93%, Expert 1: 18.75%, Expert 2: 18.70%, Expert 3: 21.31%, Expert 4: 20.30%\n",
      "2024-10-22 09:28:12,147 - INFO - MoE Layer 2 Usage: Expert 0: 20.02%, Expert 1: 19.74%, Expert 2: 19.56%, Expert 3: 21.58%, Expert 4: 19.10%\n",
      "2024-10-22 09:28:12,148 - INFO - MoE Layer 3 Usage: Expert 0: 16.28%, Expert 1: 22.40%, Expert 2: 22.59%, Expert 3: 19.84%, Expert 4: 18.90%\n",
      "2024-10-22 09:28:12,150 - INFO - MoE Layer 4 Usage: Expert 0: 21.90%, Expert 1: 20.38%, Expert 2: 19.15%, Expert 3: 24.78%, Expert 4: 13.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:16,082 - INFO - MoE Layer 1 Usage: Expert 0: 21.10%, Expert 1: 18.81%, Expert 2: 18.68%, Expert 3: 21.00%, Expert 4: 20.40%\n",
      "2024-10-22 09:28:16,083 - INFO - MoE Layer 2 Usage: Expert 0: 20.19%, Expert 1: 19.64%, Expert 2: 19.71%, Expert 3: 21.58%, Expert 4: 18.88%\n",
      "2024-10-22 09:28:16,084 - INFO - MoE Layer 3 Usage: Expert 0: 16.37%, Expert 1: 22.66%, Expert 2: 22.43%, Expert 3: 19.72%, Expert 4: 18.81%\n",
      "2024-10-22 09:28:16,085 - INFO - MoE Layer 4 Usage: Expert 0: 21.68%, Expert 1: 20.50%, Expert 2: 19.35%, Expert 3: 24.67%, Expert 4: 13.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:20,011 - INFO - MoE Layer 1 Usage: Expert 0: 21.09%, Expert 1: 18.76%, Expert 2: 18.76%, Expert 3: 20.94%, Expert 4: 20.45%\n",
      "2024-10-22 09:28:20,012 - INFO - MoE Layer 2 Usage: Expert 0: 20.48%, Expert 1: 19.82%, Expert 2: 19.07%, Expert 3: 21.69%, Expert 4: 18.95%\n",
      "2024-10-22 09:28:20,013 - INFO - MoE Layer 3 Usage: Expert 0: 16.27%, Expert 1: 22.51%, Expert 2: 22.36%, Expert 3: 19.89%, Expert 4: 18.96%\n",
      "2024-10-22 09:28:20,014 - INFO - MoE Layer 4 Usage: Expert 0: 21.68%, Expert 1: 20.51%, Expert 2: 19.44%, Expert 3: 24.59%, Expert 4: 13.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:24,019 - INFO - MoE Layer 1 Usage: Expert 0: 21.13%, Expert 1: 18.77%, Expert 2: 18.67%, Expert 3: 20.99%, Expert 4: 20.43%\n",
      "2024-10-22 09:28:24,020 - INFO - MoE Layer 2 Usage: Expert 0: 20.23%, Expert 1: 19.63%, Expert 2: 19.43%, Expert 3: 21.58%, Expert 4: 19.13%\n",
      "2024-10-22 09:28:24,021 - INFO - MoE Layer 3 Usage: Expert 0: 16.28%, Expert 1: 22.66%, Expert 2: 22.27%, Expert 3: 19.73%, Expert 4: 19.05%\n",
      "2024-10-22 09:28:24,022 - INFO - MoE Layer 4 Usage: Expert 0: 21.99%, Expert 1: 20.66%, Expert 2: 19.24%, Expert 3: 24.49%, Expert 4: 13.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:27,881 - INFO - MoE Layer 1 Usage: Expert 0: 21.11%, Expert 1: 18.85%, Expert 2: 18.68%, Expert 3: 21.03%, Expert 4: 20.33%\n",
      "2024-10-22 09:28:27,882 - INFO - MoE Layer 2 Usage: Expert 0: 20.29%, Expert 1: 19.55%, Expert 2: 19.39%, Expert 3: 21.81%, Expert 4: 18.96%\n",
      "2024-10-22 09:28:27,883 - INFO - MoE Layer 3 Usage: Expert 0: 16.33%, Expert 1: 22.41%, Expert 2: 22.47%, Expert 3: 19.93%, Expert 4: 18.86%\n",
      "2024-10-22 09:28:27,884 - INFO - MoE Layer 4 Usage: Expert 0: 21.81%, Expert 1: 20.77%, Expert 2: 19.36%, Expert 3: 24.54%, Expert 4: 13.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:31,745 - INFO - MoE Layer 1 Usage: Expert 0: 20.93%, Expert 1: 18.85%, Expert 2: 18.70%, Expert 3: 21.25%, Expert 4: 20.28%\n",
      "2024-10-22 09:28:31,746 - INFO - MoE Layer 2 Usage: Expert 0: 20.39%, Expert 1: 19.55%, Expert 2: 19.48%, Expert 3: 21.49%, Expert 4: 19.10%\n",
      "2024-10-22 09:28:31,747 - INFO - MoE Layer 3 Usage: Expert 0: 16.25%, Expert 1: 22.48%, Expert 2: 22.32%, Expert 3: 19.88%, Expert 4: 19.07%\n",
      "2024-10-22 09:28:31,748 - INFO - MoE Layer 4 Usage: Expert 0: 21.93%, Expert 1: 20.71%, Expert 2: 19.34%, Expert 3: 24.55%, Expert 4: 13.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:35,679 - INFO - MoE Layer 1 Usage: Expert 0: 21.19%, Expert 1: 18.83%, Expert 2: 18.88%, Expert 3: 20.75%, Expert 4: 20.35%\n",
      "2024-10-22 09:28:35,680 - INFO - MoE Layer 2 Usage: Expert 0: 20.32%, Expert 1: 19.79%, Expert 2: 19.28%, Expert 3: 21.69%, Expert 4: 18.92%\n",
      "2024-10-22 09:28:35,680 - INFO - MoE Layer 3 Usage: Expert 0: 16.12%, Expert 1: 22.57%, Expert 2: 22.52%, Expert 3: 20.00%, Expert 4: 18.80%\n",
      "2024-10-22 09:28:35,682 - INFO - MoE Layer 4 Usage: Expert 0: 21.81%, Expert 1: 20.68%, Expert 2: 19.31%, Expert 3: 24.74%, Expert 4: 13.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:39,534 - INFO - MoE Layer 1 Usage: Expert 0: 21.09%, Expert 1: 18.89%, Expert 2: 18.68%, Expert 3: 20.98%, Expert 4: 20.36%\n",
      "2024-10-22 09:28:39,535 - INFO - MoE Layer 2 Usage: Expert 0: 20.39%, Expert 1: 19.65%, Expert 2: 19.16%, Expert 3: 21.70%, Expert 4: 19.10%\n",
      "2024-10-22 09:28:39,536 - INFO - MoE Layer 3 Usage: Expert 0: 16.31%, Expert 1: 22.51%, Expert 2: 22.45%, Expert 3: 19.67%, Expert 4: 19.06%\n",
      "2024-10-22 09:28:39,537 - INFO - MoE Layer 4 Usage: Expert 0: 21.79%, Expert 1: 21.04%, Expert 2: 19.34%, Expert 3: 24.44%, Expert 4: 13.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:43,381 - INFO - MoE Layer 1 Usage: Expert 0: 21.17%, Expert 1: 18.79%, Expert 2: 18.73%, Expert 3: 20.99%, Expert 4: 20.32%\n",
      "2024-10-22 09:28:43,382 - INFO - MoE Layer 2 Usage: Expert 0: 20.29%, Expert 1: 19.75%, Expert 2: 19.40%, Expert 3: 21.69%, Expert 4: 18.87%\n",
      "2024-10-22 09:28:43,383 - INFO - MoE Layer 3 Usage: Expert 0: 16.10%, Expert 1: 22.60%, Expert 2: 22.46%, Expert 3: 19.88%, Expert 4: 18.96%\n",
      "2024-10-22 09:28:43,384 - INFO - MoE Layer 4 Usage: Expert 0: 22.21%, Expert 1: 20.65%, Expert 2: 19.23%, Expert 3: 24.53%, Expert 4: 13.39%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n",
      "{'loss': 5.8663, 'grad_norm': 4.364841461181641, 'learning_rate': 0.00025, 'epoch': 126.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f44af508a7461db0641a1f8b9672ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-1000\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1000\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1000\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-1000\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1000\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.708746910095215, 'eval_runtime': 0.5099, 'eval_samples_per_second': 1961.056, 'eval_steps_per_second': 66.676, 'epoch': 126.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-900] due to args.save_total_limit\n",
      "2024-10-22 09:28:48,167 - INFO - MoE Layer 1 Usage: Expert 0: 21.06%, Expert 1: 19.00%, Expert 2: 18.78%, Expert 3: 20.72%, Expert 4: 20.44%\n",
      "2024-10-22 09:28:48,168 - INFO - MoE Layer 2 Usage: Expert 0: 19.53%, Expert 1: 19.90%, Expert 2: 19.14%, Expert 3: 22.19%, Expert 4: 19.25%\n",
      "2024-10-22 09:28:48,169 - INFO - MoE Layer 3 Usage: Expert 0: 16.15%, Expert 1: 23.18%, Expert 2: 22.12%, Expert 3: 19.86%, Expert 4: 18.69%\n",
      "2024-10-22 09:28:48,170 - INFO - MoE Layer 4 Usage: Expert 0: 21.35%, Expert 1: 21.33%, Expert 2: 19.39%, Expert 3: 24.67%, Expert 4: 13.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:52,134 - INFO - MoE Layer 1 Usage: Expert 0: 21.25%, Expert 1: 18.73%, Expert 2: 18.70%, Expert 3: 20.99%, Expert 4: 20.34%\n",
      "2024-10-22 09:28:52,135 - INFO - MoE Layer 2 Usage: Expert 0: 20.31%, Expert 1: 19.79%, Expert 2: 19.38%, Expert 3: 21.52%, Expert 4: 19.00%\n",
      "2024-10-22 09:28:52,136 - INFO - MoE Layer 3 Usage: Expert 0: 15.87%, Expert 1: 22.70%, Expert 2: 22.43%, Expert 3: 20.01%, Expert 4: 18.99%\n",
      "2024-10-22 09:28:52,138 - INFO - MoE Layer 4 Usage: Expert 0: 21.95%, Expert 1: 20.52%, Expert 2: 19.19%, Expert 3: 25.01%, Expert 4: 13.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:28:56,092 - INFO - MoE Layer 1 Usage: Expert 0: 21.14%, Expert 1: 18.81%, Expert 2: 18.81%, Expert 3: 20.90%, Expert 4: 20.35%\n",
      "2024-10-22 09:28:56,093 - INFO - MoE Layer 2 Usage: Expert 0: 20.39%, Expert 1: 19.79%, Expert 2: 19.48%, Expert 3: 21.68%, Expert 4: 18.66%\n",
      "2024-10-22 09:28:56,094 - INFO - MoE Layer 3 Usage: Expert 0: 16.05%, Expert 1: 22.61%, Expert 2: 22.29%, Expert 3: 19.99%, Expert 4: 19.07%\n",
      "2024-10-22 09:28:56,095 - INFO - MoE Layer 4 Usage: Expert 0: 21.88%, Expert 1: 20.54%, Expert 2: 19.15%, Expert 3: 25.25%, Expert 4: 13.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:00,075 - INFO - MoE Layer 1 Usage: Expert 0: 21.17%, Expert 1: 18.81%, Expert 2: 18.66%, Expert 3: 21.03%, Expert 4: 20.34%\n",
      "2024-10-22 09:29:00,076 - INFO - MoE Layer 2 Usage: Expert 0: 20.29%, Expert 1: 19.76%, Expert 2: 19.32%, Expert 3: 21.72%, Expert 4: 18.92%\n",
      "2024-10-22 09:29:00,077 - INFO - MoE Layer 3 Usage: Expert 0: 16.13%, Expert 1: 22.60%, Expert 2: 22.53%, Expert 3: 19.92%, Expert 4: 18.82%\n",
      "2024-10-22 09:29:00,078 - INFO - MoE Layer 4 Usage: Expert 0: 22.08%, Expert 1: 20.69%, Expert 2: 19.13%, Expert 3: 24.83%, Expert 4: 13.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:04,001 - INFO - MoE Layer 1 Usage: Expert 0: 21.23%, Expert 1: 18.70%, Expert 2: 18.74%, Expert 3: 20.94%, Expert 4: 20.39%\n",
      "2024-10-22 09:29:04,003 - INFO - MoE Layer 2 Usage: Expert 0: 20.47%, Expert 1: 19.72%, Expert 2: 19.19%, Expert 3: 21.64%, Expert 4: 18.98%\n",
      "2024-10-22 09:29:04,004 - INFO - MoE Layer 3 Usage: Expert 0: 16.21%, Expert 1: 22.56%, Expert 2: 22.42%, Expert 3: 19.91%, Expert 4: 18.90%\n",
      "2024-10-22 09:29:04,005 - INFO - MoE Layer 4 Usage: Expert 0: 21.71%, Expert 1: 20.94%, Expert 2: 19.09%, Expert 3: 25.07%, Expert 4: 13.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:07,958 - INFO - MoE Layer 1 Usage: Expert 0: 21.20%, Expert 1: 18.81%, Expert 2: 18.84%, Expert 3: 20.86%, Expert 4: 20.29%\n",
      "2024-10-22 09:29:07,959 - INFO - MoE Layer 2 Usage: Expert 0: 20.38%, Expert 1: 19.75%, Expert 2: 19.48%, Expert 3: 21.54%, Expert 4: 18.85%\n",
      "2024-10-22 09:29:07,960 - INFO - MoE Layer 3 Usage: Expert 0: 16.00%, Expert 1: 22.59%, Expert 2: 22.33%, Expert 3: 19.98%, Expert 4: 19.10%\n",
      "2024-10-22 09:29:07,961 - INFO - MoE Layer 4 Usage: Expert 0: 21.95%, Expert 1: 20.94%, Expert 2: 19.14%, Expert 3: 24.95%, Expert 4: 13.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:11,934 - INFO - MoE Layer 1 Usage: Expert 0: 21.34%, Expert 1: 18.90%, Expert 2: 18.60%, Expert 3: 20.81%, Expert 4: 20.34%\n",
      "2024-10-22 09:29:11,935 - INFO - MoE Layer 2 Usage: Expert 0: 20.20%, Expert 1: 19.89%, Expert 2: 19.27%, Expert 3: 21.57%, Expert 4: 19.07%\n",
      "2024-10-22 09:29:11,936 - INFO - MoE Layer 3 Usage: Expert 0: 16.01%, Expert 1: 22.58%, Expert 2: 22.46%, Expert 3: 20.05%, Expert 4: 18.91%\n",
      "2024-10-22 09:29:11,937 - INFO - MoE Layer 4 Usage: Expert 0: 22.02%, Expert 1: 20.57%, Expert 2: 19.08%, Expert 3: 25.16%, Expert 4: 13.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:15,889 - INFO - MoE Layer 1 Usage: Expert 0: 21.11%, Expert 1: 18.72%, Expert 2: 18.51%, Expert 3: 21.14%, Expert 4: 20.52%\n",
      "2024-10-22 09:29:15,890 - INFO - MoE Layer 2 Usage: Expert 0: 20.30%, Expert 1: 19.65%, Expert 2: 19.51%, Expert 3: 21.68%, Expert 4: 18.87%\n",
      "2024-10-22 09:29:15,891 - INFO - MoE Layer 3 Usage: Expert 0: 15.93%, Expert 1: 22.39%, Expert 2: 22.44%, Expert 3: 20.22%, Expert 4: 19.02%\n",
      "2024-10-22 09:29:15,892 - INFO - MoE Layer 4 Usage: Expert 0: 21.68%, Expert 1: 21.11%, Expert 2: 19.18%, Expert 3: 24.82%, Expert 4: 13.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:19,895 - INFO - MoE Layer 1 Usage: Expert 0: 21.21%, Expert 1: 18.71%, Expert 2: 18.69%, Expert 3: 20.99%, Expert 4: 20.40%\n",
      "2024-10-22 09:29:19,896 - INFO - MoE Layer 2 Usage: Expert 0: 20.29%, Expert 1: 19.79%, Expert 2: 19.29%, Expert 3: 21.69%, Expert 4: 18.94%\n",
      "2024-10-22 09:29:19,896 - INFO - MoE Layer 3 Usage: Expert 0: 16.20%, Expert 1: 22.59%, Expert 2: 22.07%, Expert 3: 20.08%, Expert 4: 19.06%\n",
      "2024-10-22 09:29:19,907 - INFO - MoE Layer 4 Usage: Expert 0: 21.85%, Expert 1: 20.76%, Expert 2: 19.06%, Expert 3: 25.19%, Expert 4: 13.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:23,892 - INFO - MoE Layer 1 Usage: Expert 0: 21.29%, Expert 1: 18.51%, Expert 2: 18.66%, Expert 3: 21.18%, Expert 4: 20.36%\n",
      "2024-10-22 09:29:23,893 - INFO - MoE Layer 2 Usage: Expert 0: 20.23%, Expert 1: 19.69%, Expert 2: 19.44%, Expert 3: 21.69%, Expert 4: 18.96%\n",
      "2024-10-22 09:29:23,894 - INFO - MoE Layer 3 Usage: Expert 0: 16.11%, Expert 1: 22.70%, Expert 2: 22.18%, Expert 3: 19.94%, Expert 4: 19.08%\n",
      "2024-10-22 09:29:23,895 - INFO - MoE Layer 4 Usage: Expert 0: 21.84%, Expert 1: 20.93%, Expert 2: 19.15%, Expert 3: 25.09%, Expert 4: 12.99%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b8485d753e43f38eb9a6f017b0ffe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-1100\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1100\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1100\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-1100\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1100\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1100\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.9355340003967285, 'eval_runtime': 0.555, 'eval_samples_per_second': 1801.93, 'eval_steps_per_second': 61.266, 'epoch': 139.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-1000] due to args.save_total_limit\n",
      "2024-10-22 09:29:28,651 - INFO - MoE Layer 1 Usage: Expert 0: 20.99%, Expert 1: 18.89%, Expert 2: 19.02%, Expert 3: 20.53%, Expert 4: 20.57%\n",
      "2024-10-22 09:29:28,652 - INFO - MoE Layer 2 Usage: Expert 0: 20.04%, Expert 1: 19.77%, Expert 2: 19.18%, Expert 3: 22.27%, Expert 4: 18.74%\n",
      "2024-10-22 09:29:28,653 - INFO - MoE Layer 3 Usage: Expert 0: 15.93%, Expert 1: 23.03%, Expert 2: 22.23%, Expert 3: 20.43%, Expert 4: 18.39%\n",
      "2024-10-22 09:29:28,654 - INFO - MoE Layer 4 Usage: Expert 0: 21.63%, Expert 1: 21.22%, Expert 2: 18.69%, Expert 3: 25.31%, Expert 4: 13.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:32,550 - INFO - MoE Layer 1 Usage: Expert 0: 21.33%, Expert 1: 18.72%, Expert 2: 18.60%, Expert 3: 20.96%, Expert 4: 20.39%\n",
      "2024-10-22 09:29:32,551 - INFO - MoE Layer 2 Usage: Expert 0: 20.22%, Expert 1: 19.94%, Expert 2: 19.21%, Expert 3: 21.72%, Expert 4: 18.91%\n",
      "2024-10-22 09:29:32,552 - INFO - MoE Layer 3 Usage: Expert 0: 15.89%, Expert 1: 22.74%, Expert 2: 22.45%, Expert 3: 19.92%, Expert 4: 19.00%\n",
      "2024-10-22 09:29:32,554 - INFO - MoE Layer 4 Usage: Expert 0: 22.13%, Expert 1: 20.81%, Expert 2: 18.98%, Expert 3: 25.08%, Expert 4: 13.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:36,450 - INFO - MoE Layer 1 Usage: Expert 0: 21.21%, Expert 1: 18.82%, Expert 2: 18.55%, Expert 3: 20.91%, Expert 4: 20.50%\n",
      "2024-10-22 09:29:36,451 - INFO - MoE Layer 2 Usage: Expert 0: 20.21%, Expert 1: 19.82%, Expert 2: 19.39%, Expert 3: 21.57%, Expert 4: 19.01%\n",
      "2024-10-22 09:29:36,452 - INFO - MoE Layer 3 Usage: Expert 0: 16.21%, Expert 1: 22.38%, Expert 2: 22.35%, Expert 3: 20.01%, Expert 4: 19.05%\n",
      "2024-10-22 09:29:36,453 - INFO - MoE Layer 4 Usage: Expert 0: 21.96%, Expert 1: 20.97%, Expert 2: 19.16%, Expert 3: 24.84%, Expert 4: 13.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:40,351 - INFO - MoE Layer 1 Usage: Expert 0: 21.23%, Expert 1: 18.81%, Expert 2: 18.58%, Expert 3: 21.06%, Expert 4: 20.32%\n",
      "2024-10-22 09:29:40,352 - INFO - MoE Layer 2 Usage: Expert 0: 20.24%, Expert 1: 19.84%, Expert 2: 19.32%, Expert 3: 21.75%, Expert 4: 18.85%\n",
      "2024-10-22 09:29:40,353 - INFO - MoE Layer 3 Usage: Expert 0: 16.05%, Expert 1: 22.69%, Expert 2: 22.17%, Expert 3: 20.12%, Expert 4: 18.97%\n",
      "2024-10-22 09:29:40,355 - INFO - MoE Layer 4 Usage: Expert 0: 21.93%, Expert 1: 20.83%, Expert 2: 19.26%, Expert 3: 24.86%, Expert 4: 13.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:44,286 - INFO - MoE Layer 1 Usage: Expert 0: 21.25%, Expert 1: 18.74%, Expert 2: 18.57%, Expert 3: 21.04%, Expert 4: 20.41%\n",
      "2024-10-22 09:29:44,287 - INFO - MoE Layer 2 Usage: Expert 0: 20.37%, Expert 1: 19.57%, Expert 2: 19.39%, Expert 3: 21.60%, Expert 4: 19.06%\n",
      "2024-10-22 09:29:44,288 - INFO - MoE Layer 3 Usage: Expert 0: 16.19%, Expert 1: 22.43%, Expert 2: 22.18%, Expert 3: 20.22%, Expert 4: 18.98%\n",
      "2024-10-22 09:29:44,290 - INFO - MoE Layer 4 Usage: Expert 0: 21.87%, Expert 1: 21.03%, Expert 2: 18.91%, Expert 3: 25.11%, Expert 4: 13.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:48,232 - INFO - MoE Layer 1 Usage: Expert 0: 21.22%, Expert 1: 18.85%, Expert 2: 18.62%, Expert 3: 20.90%, Expert 4: 20.41%\n",
      "2024-10-22 09:29:48,233 - INFO - MoE Layer 2 Usage: Expert 0: 20.36%, Expert 1: 19.89%, Expert 2: 19.32%, Expert 3: 21.58%, Expert 4: 18.85%\n",
      "2024-10-22 09:29:48,234 - INFO - MoE Layer 3 Usage: Expert 0: 16.07%, Expert 1: 22.66%, Expert 2: 22.28%, Expert 3: 20.05%, Expert 4: 18.95%\n",
      "2024-10-22 09:29:48,236 - INFO - MoE Layer 4 Usage: Expert 0: 21.99%, Expert 1: 20.93%, Expert 2: 19.10%, Expert 3: 24.92%, Expert 4: 13.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:52,158 - INFO - MoE Layer 1 Usage: Expert 0: 21.20%, Expert 1: 18.62%, Expert 2: 18.52%, Expert 3: 21.22%, Expert 4: 20.44%\n",
      "2024-10-22 09:29:52,158 - INFO - MoE Layer 2 Usage: Expert 0: 20.31%, Expert 1: 19.67%, Expert 2: 19.51%, Expert 3: 21.60%, Expert 4: 18.90%\n",
      "2024-10-22 09:29:52,159 - INFO - MoE Layer 3 Usage: Expert 0: 16.07%, Expert 1: 22.52%, Expert 2: 22.56%, Expert 3: 19.88%, Expert 4: 18.97%\n",
      "2024-10-22 09:29:52,161 - INFO - MoE Layer 4 Usage: Expert 0: 22.04%, Expert 1: 21.12%, Expert 2: 18.65%, Expert 3: 25.32%, Expert 4: 12.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:29:56,132 - INFO - MoE Layer 1 Usage: Expert 0: 21.48%, Expert 1: 18.82%, Expert 2: 18.30%, Expert 3: 20.89%, Expert 4: 20.51%\n",
      "2024-10-22 09:29:56,133 - INFO - MoE Layer 2 Usage: Expert 0: 20.26%, Expert 1: 19.77%, Expert 2: 19.24%, Expert 3: 21.70%, Expert 4: 19.03%\n",
      "2024-10-22 09:29:56,134 - INFO - MoE Layer 3 Usage: Expert 0: 16.04%, Expert 1: 22.49%, Expert 2: 22.45%, Expert 3: 19.99%, Expert 4: 19.03%\n",
      "2024-10-22 09:29:56,136 - INFO - MoE Layer 4 Usage: Expert 0: 21.93%, Expert 1: 21.22%, Expert 2: 18.93%, Expert 3: 25.01%, Expert 4: 12.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:00,040 - INFO - MoE Layer 1 Usage: Expert 0: 21.34%, Expert 1: 18.60%, Expert 2: 18.58%, Expert 3: 21.01%, Expert 4: 20.47%\n",
      "2024-10-22 09:30:00,041 - INFO - MoE Layer 2 Usage: Expert 0: 20.21%, Expert 1: 19.89%, Expert 2: 19.40%, Expert 3: 21.49%, Expert 4: 19.01%\n",
      "2024-10-22 09:30:00,042 - INFO - MoE Layer 3 Usage: Expert 0: 16.02%, Expert 1: 22.70%, Expert 2: 22.47%, Expert 3: 20.01%, Expert 4: 18.79%\n",
      "2024-10-22 09:30:00,043 - INFO - MoE Layer 4 Usage: Expert 0: 21.95%, Expert 1: 20.90%, Expert 2: 18.67%, Expert 3: 25.35%, Expert 4: 13.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:04,003 - INFO - MoE Layer 1 Usage: Expert 0: 21.19%, Expert 1: 18.80%, Expert 2: 18.43%, Expert 3: 21.16%, Expert 4: 20.41%\n",
      "2024-10-22 09:30:04,004 - INFO - MoE Layer 2 Usage: Expert 0: 20.39%, Expert 1: 19.71%, Expert 2: 19.29%, Expert 3: 21.70%, Expert 4: 18.91%\n",
      "2024-10-22 09:30:04,004 - INFO - MoE Layer 3 Usage: Expert 0: 16.13%, Expert 1: 22.50%, Expert 2: 22.55%, Expert 3: 19.92%, Expert 4: 18.91%\n",
      "2024-10-22 09:30:04,006 - INFO - MoE Layer 4 Usage: Expert 0: 22.12%, Expert 1: 21.04%, Expert 2: 18.60%, Expert 3: 25.36%, Expert 4: 12.88%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bd1928a5be4d0cb25c37edb7b88158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-1200\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1200\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1200\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-1200\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1200\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1200\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.256348609924316, 'eval_runtime': 0.5411, 'eval_samples_per_second': 1848.009, 'eval_steps_per_second': 62.832, 'epoch': 151.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-1100] due to args.save_total_limit\n",
      "2024-10-22 09:30:08,866 - INFO - MoE Layer 1 Usage: Expert 0: 21.18%, Expert 1: 18.84%, Expert 2: 18.81%, Expert 3: 20.70%, Expert 4: 20.46%\n",
      "2024-10-22 09:30:08,867 - INFO - MoE Layer 2 Usage: Expert 0: 19.85%, Expert 1: 19.87%, Expert 2: 18.96%, Expert 3: 22.22%, Expert 4: 19.09%\n",
      "2024-10-22 09:30:08,868 - INFO - MoE Layer 3 Usage: Expert 0: 15.99%, Expert 1: 23.22%, Expert 2: 22.03%, Expert 3: 20.22%, Expert 4: 18.54%\n",
      "2024-10-22 09:30:08,869 - INFO - MoE Layer 4 Usage: Expert 0: 21.81%, Expert 1: 21.08%, Expert 2: 18.94%, Expert 3: 25.16%, Expert 4: 13.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:12,798 - INFO - MoE Layer 1 Usage: Expert 0: 21.34%, Expert 1: 18.62%, Expert 2: 18.53%, Expert 3: 21.13%, Expert 4: 20.38%\n",
      "2024-10-22 09:30:12,799 - INFO - MoE Layer 2 Usage: Expert 0: 20.30%, Expert 1: 19.89%, Expert 2: 19.29%, Expert 3: 21.71%, Expert 4: 18.82%\n",
      "2024-10-22 09:30:12,800 - INFO - MoE Layer 3 Usage: Expert 0: 16.04%, Expert 1: 22.52%, Expert 2: 22.27%, Expert 3: 19.96%, Expert 4: 19.21%\n",
      "2024-10-22 09:30:12,801 - INFO - MoE Layer 4 Usage: Expert 0: 22.30%, Expert 1: 20.95%, Expert 2: 18.72%, Expert 3: 25.12%, Expert 4: 12.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:16,725 - INFO - MoE Layer 1 Usage: Expert 0: 21.39%, Expert 1: 18.74%, Expert 2: 18.51%, Expert 3: 21.14%, Expert 4: 20.22%\n",
      "2024-10-22 09:30:16,726 - INFO - MoE Layer 2 Usage: Expert 0: 20.41%, Expert 1: 19.79%, Expert 2: 19.31%, Expert 3: 21.64%, Expert 4: 18.85%\n",
      "2024-10-22 09:30:16,727 - INFO - MoE Layer 3 Usage: Expert 0: 16.18%, Expert 1: 22.47%, Expert 2: 22.30%, Expert 3: 20.05%, Expert 4: 19.00%\n",
      "2024-10-22 09:30:16,728 - INFO - MoE Layer 4 Usage: Expert 0: 22.05%, Expert 1: 20.97%, Expert 2: 18.75%, Expert 3: 25.35%, Expert 4: 12.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:20,733 - INFO - MoE Layer 1 Usage: Expert 0: 21.40%, Expert 1: 18.77%, Expert 2: 18.62%, Expert 3: 20.82%, Expert 4: 20.39%\n",
      "2024-10-22 09:30:20,734 - INFO - MoE Layer 2 Usage: Expert 0: 20.35%, Expert 1: 19.80%, Expert 2: 19.13%, Expert 3: 21.81%, Expert 4: 18.90%\n",
      "2024-10-22 09:30:20,735 - INFO - MoE Layer 3 Usage: Expert 0: 16.06%, Expert 1: 22.42%, Expert 2: 22.26%, Expert 3: 20.20%, Expert 4: 19.06%\n",
      "2024-10-22 09:30:20,736 - INFO - MoE Layer 4 Usage: Expert 0: 22.28%, Expert 1: 20.84%, Expert 2: 18.78%, Expert 3: 25.23%, Expert 4: 12.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:24,637 - INFO - MoE Layer 1 Usage: Expert 0: 21.27%, Expert 1: 18.69%, Expert 2: 18.48%, Expert 3: 21.07%, Expert 4: 20.49%\n",
      "2024-10-22 09:30:24,638 - INFO - MoE Layer 2 Usage: Expert 0: 20.18%, Expert 1: 19.93%, Expert 2: 19.26%, Expert 3: 21.66%, Expert 4: 18.97%\n",
      "2024-10-22 09:30:24,639 - INFO - MoE Layer 3 Usage: Expert 0: 16.13%, Expert 1: 22.44%, Expert 2: 22.43%, Expert 3: 19.85%, Expert 4: 19.15%\n",
      "2024-10-22 09:30:24,640 - INFO - MoE Layer 4 Usage: Expert 0: 22.27%, Expert 1: 21.16%, Expert 2: 18.69%, Expert 3: 24.86%, Expert 4: 13.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:28,545 - INFO - MoE Layer 1 Usage: Expert 0: 21.32%, Expert 1: 18.75%, Expert 2: 18.63%, Expert 3: 20.93%, Expert 4: 20.37%\n",
      "2024-10-22 09:30:28,546 - INFO - MoE Layer 2 Usage: Expert 0: 20.34%, Expert 1: 19.75%, Expert 2: 19.49%, Expert 3: 21.60%, Expert 4: 18.82%\n",
      "2024-10-22 09:30:28,546 - INFO - MoE Layer 3 Usage: Expert 0: 16.00%, Expert 1: 22.56%, Expert 2: 22.28%, Expert 3: 20.02%, Expert 4: 19.13%\n",
      "2024-10-22 09:30:28,547 - INFO - MoE Layer 4 Usage: Expert 0: 22.32%, Expert 1: 21.15%, Expert 2: 18.58%, Expert 3: 25.07%, Expert 4: 12.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:32,506 - INFO - MoE Layer 1 Usage: Expert 0: 21.27%, Expert 1: 18.79%, Expert 2: 18.53%, Expert 3: 21.10%, Expert 4: 20.30%\n",
      "2024-10-22 09:30:32,507 - INFO - MoE Layer 2 Usage: Expert 0: 20.21%, Expert 1: 19.75%, Expert 2: 19.32%, Expert 3: 21.94%, Expert 4: 18.77%\n",
      "2024-10-22 09:30:32,508 - INFO - MoE Layer 3 Usage: Expert 0: 16.10%, Expert 1: 22.25%, Expert 2: 22.45%, Expert 3: 20.01%, Expert 4: 19.19%\n",
      "2024-10-22 09:30:32,509 - INFO - MoE Layer 4 Usage: Expert 0: 21.99%, Expert 1: 21.27%, Expert 2: 18.91%, Expert 3: 24.74%, Expert 4: 13.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:36,448 - INFO - MoE Layer 1 Usage: Expert 0: 21.19%, Expert 1: 18.86%, Expert 2: 18.51%, Expert 3: 21.10%, Expert 4: 20.34%\n",
      "2024-10-22 09:30:36,449 - INFO - MoE Layer 2 Usage: Expert 0: 20.43%, Expert 1: 19.77%, Expert 2: 19.33%, Expert 3: 21.62%, Expert 4: 18.85%\n",
      "2024-10-22 09:30:36,450 - INFO - MoE Layer 3 Usage: Expert 0: 16.01%, Expert 1: 22.63%, Expert 2: 22.32%, Expert 3: 20.14%, Expert 4: 18.89%\n",
      "2024-10-22 09:30:36,451 - INFO - MoE Layer 4 Usage: Expert 0: 22.35%, Expert 1: 21.22%, Expert 2: 18.61%, Expert 3: 25.08%, Expert 4: 12.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:40,417 - INFO - MoE Layer 1 Usage: Expert 0: 21.21%, Expert 1: 18.67%, Expert 2: 18.73%, Expert 3: 20.93%, Expert 4: 20.47%\n",
      "2024-10-22 09:30:40,418 - INFO - MoE Layer 2 Usage: Expert 0: 20.32%, Expert 1: 19.81%, Expert 2: 19.42%, Expert 3: 21.66%, Expert 4: 18.78%\n",
      "2024-10-22 09:30:40,419 - INFO - MoE Layer 3 Usage: Expert 0: 16.36%, Expert 1: 22.63%, Expert 2: 22.42%, Expert 3: 19.83%, Expert 4: 18.76%\n",
      "2024-10-22 09:30:40,421 - INFO - MoE Layer 4 Usage: Expert 0: 22.47%, Expert 1: 21.03%, Expert 2: 18.37%, Expert 3: 25.18%, Expert 4: 12.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:44,414 - INFO - MoE Layer 1 Usage: Expert 0: 21.44%, Expert 1: 18.82%, Expert 2: 18.39%, Expert 3: 20.99%, Expert 4: 20.37%\n",
      "2024-10-22 09:30:44,415 - INFO - MoE Layer 2 Usage: Expert 0: 20.32%, Expert 1: 20.02%, Expert 2: 19.12%, Expert 3: 21.67%, Expert 4: 18.87%\n",
      "2024-10-22 09:30:44,416 - INFO - MoE Layer 3 Usage: Expert 0: 16.13%, Expert 1: 22.38%, Expert 2: 22.32%, Expert 3: 20.10%, Expert 4: 19.07%\n",
      "2024-10-22 09:30:44,417 - INFO - MoE Layer 4 Usage: Expert 0: 22.37%, Expert 1: 20.98%, Expert 2: 18.53%, Expert 3: 25.35%, Expert 4: 12.78%\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad04fc94927a4fada4a4872f09d13ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/pretraining_moe/checkpoints\\checkpoint-1300\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1300\\config.json\n",
      "Configuration saved in ./results/pretraining_moe/checkpoints\\checkpoint-1300\\generation_config.json\n",
      "Model weights saved in ./results/pretraining_moe/checkpoints\\checkpoint-1300\\model.safetensors\n",
      "tokenizer config file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1300\\tokenizer_config.json\n",
      "Special tokens file saved in ./results/pretraining_moe/checkpoints\\checkpoint-1300\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.439208984375, 'eval_runtime': 0.5095, 'eval_samples_per_second': 1962.531, 'eval_steps_per_second': 66.726, 'epoch': 164.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [results\\pretraining_moe\\checkpoints\\checkpoint-1200] due to args.save_total_limit\n",
      "2024-10-22 09:30:49,107 - INFO - MoE Layer 1 Usage: Expert 0: 21.22%, Expert 1: 18.88%, Expert 2: 18.74%, Expert 3: 20.64%, Expert 4: 20.51%\n",
      "2024-10-22 09:30:49,108 - INFO - MoE Layer 2 Usage: Expert 0: 19.91%, Expert 1: 19.88%, Expert 2: 19.42%, Expert 3: 22.25%, Expert 4: 18.54%\n",
      "2024-10-22 09:30:49,109 - INFO - MoE Layer 3 Usage: Expert 0: 15.97%, Expert 1: 23.22%, Expert 2: 22.03%, Expert 3: 20.14%, Expert 4: 18.64%\n",
      "2024-10-22 09:30:49,110 - INFO - MoE Layer 4 Usage: Expert 0: 22.26%, Expert 1: 20.97%, Expert 2: 18.61%, Expert 3: 25.40%, Expert 4: 12.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:52,902 - INFO - MoE Layer 1 Usage: Expert 0: 21.24%, Expert 1: 18.89%, Expert 2: 18.30%, Expert 3: 21.12%, Expert 4: 20.44%\n",
      "2024-10-22 09:30:52,903 - INFO - MoE Layer 2 Usage: Expert 0: 20.32%, Expert 1: 20.17%, Expert 2: 18.98%, Expert 3: 21.81%, Expert 4: 18.71%\n",
      "2024-10-22 09:30:52,904 - INFO - MoE Layer 3 Usage: Expert 0: 16.03%, Expert 1: 22.47%, Expert 2: 22.48%, Expert 3: 20.06%, Expert 4: 18.96%\n",
      "2024-10-22 09:30:52,905 - INFO - MoE Layer 4 Usage: Expert 0: 22.44%, Expert 1: 21.15%, Expert 2: 18.43%, Expert 3: 25.06%, Expert 4: 12.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:30:56,723 - INFO - MoE Layer 1 Usage: Expert 0: 21.34%, Expert 1: 18.72%, Expert 2: 18.50%, Expert 3: 21.06%, Expert 4: 20.39%\n",
      "2024-10-22 09:30:56,724 - INFO - MoE Layer 2 Usage: Expert 0: 20.30%, Expert 1: 19.86%, Expert 2: 19.13%, Expert 3: 21.87%, Expert 4: 18.83%\n",
      "2024-10-22 09:30:56,725 - INFO - MoE Layer 3 Usage: Expert 0: 16.23%, Expert 1: 22.53%, Expert 2: 22.42%, Expert 3: 19.88%, Expert 4: 18.94%\n",
      "2024-10-22 09:30:56,726 - INFO - MoE Layer 4 Usage: Expert 0: 22.53%, Expert 1: 21.01%, Expert 2: 18.52%, Expert 3: 24.89%, Expert 4: 13.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:31:00,516 - INFO - MoE Layer 1 Usage: Expert 0: 21.37%, Expert 1: 18.77%, Expert 2: 18.45%, Expert 3: 20.93%, Expert 4: 20.48%\n",
      "2024-10-22 09:31:00,517 - INFO - MoE Layer 2 Usage: Expert 0: 20.44%, Expert 1: 19.86%, Expert 2: 19.28%, Expert 3: 21.66%, Expert 4: 18.77%\n",
      "2024-10-22 09:31:00,517 - INFO - MoE Layer 3 Usage: Expert 0: 16.09%, Expert 1: 22.64%, Expert 2: 22.25%, Expert 3: 19.94%, Expert 4: 19.07%\n",
      "2024-10-22 09:31:00,519 - INFO - MoE Layer 4 Usage: Expert 0: 22.45%, Expert 1: 21.02%, Expert 2: 18.41%, Expert 3: 25.28%, Expert 4: 12.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 09:31:04,314 - INFO - MoE Layer 1 Usage: Expert 0: 21.47%, Expert 1: 18.68%, Expert 2: 18.28%, Expert 3: 21.09%, Expert 4: 20.48%\n",
      "2024-10-22 09:31:04,315 - INFO - MoE Layer 2 Usage: Expert 0: 20.31%, Expert 1: 19.79%, Expert 2: 19.19%, Expert 3: 21.77%, Expert 4: 18.94%\n",
      "2024-10-22 09:31:04,316 - INFO - MoE Layer 3 Usage: Expert 0: 16.00%, Expert 1: 22.51%, Expert 2: 22.22%, Expert 3: 20.23%, Expert 4: 19.05%\n",
      "2024-10-22 09:31:04,317 - INFO - MoE Layer 4 Usage: Expert 0: 22.41%, Expert 1: 21.26%, Expert 2: 18.13%, Expert 3: 25.32%, Expert 4: 12.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging MoE usage stats...\n"
     ]
    }
   ],
   "source": [
    "# Load config using OmegaConf\n",
    "config_file = 'config.yaml'  # Path to your config file\n",
    "cfg = OmegaConf.load(config_file)\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add special tokens, such as PAD token (if not already present)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})  # Set pad token to eos token\n",
    "\n",
    "\n",
    "block_size = 128\n",
    "\n",
    "# Prepare the model configuration\n",
    "model_config = GPTConfig(**cfg.model)\n",
    "model = GPTLMHeadModel(model_config)\n",
    "train_dataset = NumpyMemmapDataset(**cfg.dataset.train)\n",
    "eval_dataset = NumpyMemmapDataset(**cfg.dataset.eval)\n",
    "training_args = TrainingArguments(**cfg.train.training_args)\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")\n",
    "\n",
    "# Optional MoE logging callback\n",
    "moe_logging_callback = MoEUsageLoggingCallback(\n",
    "    trainer=trainer, logger=logger,**cfg.train.moe_log\n",
    ")\n",
    "trainer.add_callback(moe_logging_callback)\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.model.save_pretrained(cfg.train.model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-moe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
